{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Image Example: Tiny ImageNet\n",
    "\n",
    "* _Author_: Sebastian Nowozin (Sebastian.Nowozin@microsoft.com)\n",
    "* _Date_: 16th July 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (2.0)\r\n",
      "Requirement already satisfied: numpy in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboardX) (1.18.3)\r\n",
      "Requirement already satisfied: six in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboardX) (1.12.0)\r\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboardX) (3.11.3)\r\n",
      "Requirement already satisfied: setuptools in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorboardX) (41.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "tinyimagenet = torchvision.datasets.ImageFolder('../data/tiny-imagenet-200/train',\n",
    "    transform=transform)\n",
    "len(tinyimagenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConjugateDualFunction:\n",
    "    def __init__(self, divergence_name):\n",
    "        self.divergence_name = divergence_name\n",
    "\n",
    "    def T(self, v):\n",
    "        \"\"\"Compute T(v) repersentation\n",
    "        \n",
    "        Arguments\n",
    "        v -- The scalar output (full real number range) of the discriminator\n",
    "        \"\"\"\n",
    "        if self.divergence_name == \"kl\":\n",
    "            return v\n",
    "        elif self.divergence_name == \"klrev\":\n",
    "            return -F.exp(v)\n",
    "        elif self.divergence_name == \"pearson\":\n",
    "            return v\n",
    "        elif self.divergence_name == \"neyman\":\n",
    "            return 1.0 - F.exp(v)\n",
    "        elif self.divergence_name == \"hellinger\":\n",
    "            return 1.0 - F.exp(v)\n",
    "        elif self.divergence_name == \"jensen\":\n",
    "            return math.log(2.0) - F.softplus(-v)\n",
    "        elif self.divergence_name == \"gan\":\n",
    "            return -F.softplus(-v)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown divergence name in t function.\")\n",
    "\n",
    "    def fstarT(self, v):\n",
    "        \"\"\"Compute the f^*(T(v)) representation\n",
    "        \n",
    "        Arguments\n",
    "        v -- The scalar output of the variational function neural network.\n",
    "        \"\"\"\n",
    "        if self.divergence_name == \"kl\":\n",
    "            return torch.exp(v - 1.0)\n",
    "        elif self.divergence_name == \"klrev\":\n",
    "            return -1.0 - v\n",
    "        elif self.divergence_name == \"pearson\":\n",
    "            return 0.25*v*v + v\n",
    "        elif self.divergence_name == \"neyman\":\n",
    "            return 2.0 - 2.0*F.exp(0.5*v)\n",
    "        elif self.divergence_name == \"hellinger\":\n",
    "            return F.exp(-v) - 1.0\n",
    "        elif self.divergence_name == \"jensen\":\n",
    "            return F.softplus(v) - math.log(2.0)\n",
    "        elif self.divergence_name == \"gan\":\n",
    "            return F.softplus(v)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown divergence name in fstar_t function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANGenerator(nn.Module):\n",
    "    def __init__(self, nrand):\n",
    "        super(DCGANGenerator, self).__init__()\n",
    "        self.lin1 = nn.Linear(nrand, 4*4*512)\n",
    "        init.xavier_uniform_(self.lin1.weight, gain=0.1)\n",
    "        self.lin1bn = nn.BatchNorm1d(4*4*512)\n",
    "        self.dc1 = nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1)\n",
    "        self.dc1bn = nn.BatchNorm2d(256)\n",
    "        self.dc2 = nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1)\n",
    "        self.dc2bn = nn.BatchNorm2d(128)\n",
    "        self.dc3 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1)\n",
    "        self.dc3bn = nn.BatchNorm2d(64)\n",
    "        self.dc4a = nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1)\n",
    "        self.dc4abn = nn.BatchNorm2d(32)\n",
    "        self.dc4b = nn.Conv2d(32, 3, 3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = F.relu(self.lin1bn(self.lin1(z)))\n",
    "        h = torch.reshape(h, (-1, 512, 4, 4))\n",
    "\n",
    "        # deconv stack\n",
    "        h = F.relu(self.dc1bn(self.dc1(h)))\n",
    "        h = F.relu(self.dc2bn(self.dc2(h)))\n",
    "        h = F.relu(self.dc3bn(self.dc3(h)))\n",
    "        h = F.relu(self.dc4abn(self.dc4a(h)))\n",
    "        x = self.dc4b(h)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DCGANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DCGANDiscriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 4, stride=2, padding=1)\n",
    "        self.conv1bn = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 4, stride=2, padding=1)\n",
    "        self.conv2bn = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 4, stride=2, padding=1)\n",
    "        self.conv3bn = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, 4, stride=2, padding=1)\n",
    "        self.conv4bn = nn.BatchNorm2d(512)\n",
    "        self.lin1 = nn.Linear(4*4*512, 512)\n",
    "        self.lin1bn = nn.BatchNorm1d(512)\n",
    "        self.lin2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.elu(self.conv1bn(self.conv1(x)))\n",
    "        h = F.elu(self.conv2bn(self.conv2(h)))\n",
    "        h = F.elu(self.conv3bn(self.conv3(h)))\n",
    "        h = F.elu(self.conv4bn(self.conv4(h)))\n",
    "        h = torch.reshape(h, (-1, 4*4*512))\n",
    "\n",
    "        h = F.elu(self.lin1bn(self.lin1(h)))\n",
    "        v = self.lin2(h)\n",
    "\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGANLearningObjective(nn.Module):\n",
    "    def __init__(self, gen, disc, divergence_name=\"gan\", gamma=10.0):\n",
    "        super(FGANLearningObjective, self).__init__()\n",
    "        self.gen = gen\n",
    "        self.disc = disc\n",
    "        self.conj = ConjugateDualFunction(divergence_name)\n",
    "        self.gammahalf = 0.5*gamma\n",
    "\n",
    "    def forward(self, xreal, zmodel):\n",
    "        # Real data\n",
    "        vreal = self.disc(xreal)    # Real data discriminator output\n",
    "        Treal = self.conj.T(vreal)  # Mapped to T-space\n",
    "\n",
    "        # Model data\n",
    "        xmodel = self.gen(zmodel)   # Map noise to data\n",
    "        vmodel = self.disc(xmodel)  # Model data discriminator output\n",
    "        fstar_Tmodel = self.conj.fstarT(vmodel)   # Mapped to f^*(T)\n",
    "\n",
    "        # Compute generator loss\n",
    "        loss_gen = -fstar_Tmodel.mean()\n",
    "\n",
    "        # Compute discriminator loss (negation because we minimize)\n",
    "        loss_disc = fstar_Tmodel.mean() - Treal.mean()\n",
    "\n",
    "        # Compute gradient penalty as per (Mescheder et al., ICML 2018)\n",
    "        if self.gammahalf > 0.0:\n",
    "            batchsize = xreal.size(0)\n",
    "            grad_pd = torch.autograd.grad(Treal.sum(), xreal,\n",
    "                create_graph=True, only_inputs=True)[0]\n",
    "            grad_pd_norm2 = grad_pd.pow(2)\n",
    "            grad_pd_norm2 = grad_pd_norm2.view(batchsize, -1).sum(1)\n",
    "            gradient_penalty = self.gammahalf * grad_pd_norm2.mean()\n",
    "            loss_disc += gradient_penalty\n",
    "\n",
    "        return loss_gen, loss_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrand = 128\n",
    "gen = DCGANGenerator(nrand)\n",
    "disc = DCGANDiscriminator()\n",
    "fgan = FGANLearningObjective(gen, disc, \"gan\", gamma=1000.0)\n",
    "fgan = fgan.to(device)\n",
    "#fgan = torch.nn.DataParallel(fgan)\n",
    "#fgan.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "#optimizer_gen = optim.Adam(fgan.gen.parameters(), lr=1.0e-2)\n",
    "#optimizer_disc = optim.Adam(fgan.disc.parameters(), lr=1.0e-2)\n",
    "optimizer_gen = optim.RMSprop(fgan.gen.parameters(), lr=1.0e-2)\n",
    "optimizer_disc = optim.RMSprop(fgan.disc.parameters(), lr=1.0e-2)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(tinyimagenet,\n",
    "    batch_size=batchsize, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  iter 1  obj(D) 1.5685  obj(G) -0.7988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sofiapaganin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/sofiapaganin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/sofiapaganin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/sofiapaganin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/sofiapaganin/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/sofiapaganin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/sofiapaganin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/sofiapaganin/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ce78601697e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mfgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss_disc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer_disc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=\"runs/TinyImageNet\", comment=\"f-GAN-JS\")\n",
    "\n",
    "nepochs = 2\n",
    "niter = 0\n",
    "for epoch in range(nepochs):\n",
    "    zmodel = Variable(torch.rand((batchsize,nrand), device=device))\n",
    "    xmodel = fgan.gen(zmodel)\n",
    "    xmodelimg = vutils.make_grid(xmodel,\n",
    "        normalize=True, scale_each=True)\n",
    "    writer.add_image('Generated', xmodelimg, global_step=niter)\n",
    "    #writer.file_writer.flush()\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        niter += 1\n",
    "        imgs, labels = data\n",
    "\n",
    "        fgan.zero_grad()\n",
    "\n",
    "        # Generate real data (from known distribution) and noise\n",
    "        xreal = Variable(imgs.to(device), requires_grad=True)\n",
    "        zmodel = Variable(torch.rand((batchsize,nrand), device=device))\n",
    "\n",
    "        loss_gen, loss_disc = fgan(xreal, zmodel)\n",
    "        writer.add_scalar('obj/disc', loss_disc, niter)\n",
    "        writer.add_scalar('obj/gen', loss_gen, niter)\n",
    "        if i == 0:\n",
    "            print(\"epoch %d  iter %d  obj(D) %.4f  obj(G) %.4f\" % (epoch, niter, loss_disc, loss_gen))\n",
    "#         if i %10 == 0:\n",
    "#         print(\"POOPOO\")\n",
    "        fgan.gen.zero_grad()\n",
    "        loss_gen.backward(retain_graph=True)\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        fgan.disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        #if epoch == 0 and i == 0:\n",
    "        #    writer.add_graph(fgan, input_to_model=(xreal,zmodel))\n",
    "\n",
    "writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
