{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train import *\n",
    "from models import *\n",
    "from tools import load_data, get_label_dict, get_word_labels\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data\n",
      "\n",
      "Finished loading train data\n",
      "\n",
      "Loading val data\n",
      "\n",
      "Finished loading val data\n",
      "\n",
      "Loading test data\n",
      "\n",
      "Finished loading test data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data()\n",
    "X_val, y_val = load_data(\"val\")\n",
    "X_test, _ = load_data(\"test\")\n",
    "\n",
    "y_train = to_categorical(y_train, 200)\n",
    "y_val = to_categorical(y_val, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels\n",
      "\n",
      "Done\n",
      "\n",
      "Loading words\n",
      "\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = get_label_dict()\n",
    "words = get_word_labels()\n",
    "\n",
    "test_images = os.listdir(\"data/tiny-imagenet-200/test/images/\")\n",
    "assert len(X_test) == len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing for the data\n",
    "datagen = ImageDataGenerator(rotation_range=40, \n",
    "                             brightness_range=[0.6, 1.4], \n",
    "                             shear_range=0.2, \n",
    "                             zoom_range=0.2, \n",
    "                             horizontal_flip=True, \n",
    "                             vertical_flip=True, \n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2, \n",
    "                             channel_shift_range=90., \n",
    "                             fill_mode=\"reflect\", \n",
    "                             preprocessing_function=shuffle_channels, \n",
    "                             rescale=1./255)\n",
    "\n",
    "testgen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "data = {\"train\": (X_train, y_train), \n",
    "        \"val\": (X_val, y_val)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlphaNet()\n",
    "model.name = \"AlphaNet_v2\"\n",
    "model_prefix = \"models/\" + model.name + \"/\" + model.name\n",
    "model_path = model_prefix + \".h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint callback to only save best model\n",
    "checkpoint = ModelCheckpoint(model_path, \n",
    "                             monitor=\"val_accuracy\", \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode=\"auto\", \n",
    "                             period=1)\n",
    "\n",
    "cb_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AlphaNet_v2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 32)        4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_5 (Spatial (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_6 (Spatial (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_7 (Spatial (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_8 (Spatial (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2048)              16779264  \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 200)               409800    \n",
      "=================================================================\n",
      "Total params: 23,010,952\n",
      "Trainable params: 23,000,776\n",
      "Non-trainable params: 10,176\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "3125/3125 [==============================] - 211s 68ms/step - loss: 5.8473 - accuracy: 0.0057 - top3_accuracy: 0.0164 - top5_accuracy: 0.0267 - val_loss: 5.2481 - val_accuracy: 0.0054 - val_top3_accuracy: 0.0177 - val_top5_accuracy: 0.0307\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.00540, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 2/300\n",
      "3125/3125 [==============================] - 204s 65ms/step - loss: 5.4459 - accuracy: 0.0066 - top3_accuracy: 0.0199 - top5_accuracy: 0.0327 - val_loss: 5.2842 - val_accuracy: 0.0104 - val_top3_accuracy: 0.0289 - val_top5_accuracy: 0.0455\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.00540 to 0.01040, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 3/300\n",
      "3125/3125 [==============================] - 203s 65ms/step - loss: 5.2845 - accuracy: 0.0107 - top3_accuracy: 0.0300 - top5_accuracy: 0.0479 - val_loss: 5.3531 - val_accuracy: 0.0159 - val_top3_accuracy: 0.0469 - val_top5_accuracy: 0.0698\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.01040 to 0.01590, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 4/300\n",
      "3125/3125 [==============================] - 207s 66ms/step - loss: 5.2046 - accuracy: 0.0147 - top3_accuracy: 0.0400 - top5_accuracy: 0.0628 - val_loss: 5.0580 - val_accuracy: 0.0188 - val_top3_accuracy: 0.0550 - val_top5_accuracy: 0.0838\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.01590 to 0.01880, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 5/300\n",
      "3125/3125 [==============================] - 204s 65ms/step - loss: 5.1193 - accuracy: 0.0199 - top3_accuracy: 0.0538 - top5_accuracy: 0.0825 - val_loss: 4.9926 - val_accuracy: 0.0305 - val_top3_accuracy: 0.0759 - val_top5_accuracy: 0.1125\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.01880 to 0.03050, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 6/300\n",
      "3125/3125 [==============================] - 202s 65ms/step - loss: 5.0214 - accuracy: 0.0276 - top3_accuracy: 0.0688 - top5_accuracy: 0.1037 - val_loss: 4.7105 - val_accuracy: 0.0418 - val_top3_accuracy: 0.1016 - val_top5_accuracy: 0.1478\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.03050 to 0.04180, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 7/300\n",
      "3125/3125 [==============================] - 208s 67ms/step - loss: 4.9520 - accuracy: 0.0329 - top3_accuracy: 0.0811 - top5_accuracy: 0.1202 - val_loss: 4.6397 - val_accuracy: 0.0473 - val_top3_accuracy: 0.1124 - val_top5_accuracy: 0.1610\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.04180 to 0.04730, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 8/300\n",
      "3125/3125 [==============================] - 193s 62ms/step - loss: 4.8971 - accuracy: 0.0364 - top3_accuracy: 0.0892 - top5_accuracy: 0.1319 - val_loss: 4.9227 - val_accuracy: 0.0549 - val_top3_accuracy: 0.1232 - val_top5_accuracy: 0.1750\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.04730 to 0.05490, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 9/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.8401 - accuracy: 0.0423 - top3_accuracy: 0.1002 - top5_accuracy: 0.1455 - val_loss: 4.7969 - val_accuracy: 0.0579 - val_top3_accuracy: 0.1280 - val_top5_accuracy: 0.1799\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.05490 to 0.05790, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 10/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.8067 - accuracy: 0.0445 - top3_accuracy: 0.1058 - top5_accuracy: 0.1529 - val_loss: 4.8391 - val_accuracy: 0.0507 - val_top3_accuracy: 0.1178 - val_top5_accuracy: 0.1646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.05790\n",
      "Epoch 11/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.7690 - accuracy: 0.0485 - top3_accuracy: 0.1127 - top5_accuracy: 0.1626 - val_loss: 4.6336 - val_accuracy: 0.0522 - val_top3_accuracy: 0.1241 - val_top5_accuracy: 0.1749\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.05790\n",
      "Epoch 12/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.7411 - accuracy: 0.0519 - top3_accuracy: 0.1187 - top5_accuracy: 0.1700 - val_loss: 4.8033 - val_accuracy: 0.0627 - val_top3_accuracy: 0.1385 - val_top5_accuracy: 0.1971\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.05790 to 0.06270, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 13/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.7150 - accuracy: 0.0552 - top3_accuracy: 0.1248 - top5_accuracy: 0.1771 - val_loss: 5.0166 - val_accuracy: 0.0709 - val_top3_accuracy: 0.1534 - val_top5_accuracy: 0.2172\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.06270 to 0.07090, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 14/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.6854 - accuracy: 0.0574 - top3_accuracy: 0.1292 - top5_accuracy: 0.1830 - val_loss: 4.4887 - val_accuracy: 0.0656 - val_top3_accuracy: 0.1450 - val_top5_accuracy: 0.2026\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.07090\n",
      "Epoch 15/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.6637 - accuracy: 0.0589 - top3_accuracy: 0.1339 - top5_accuracy: 0.1893 - val_loss: 4.6168 - val_accuracy: 0.0775 - val_top3_accuracy: 0.1699 - val_top5_accuracy: 0.2351\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.07090 to 0.07750, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 16/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.6426 - accuracy: 0.0621 - top3_accuracy: 0.1383 - top5_accuracy: 0.1941 - val_loss: 4.8416 - val_accuracy: 0.0547 - val_top3_accuracy: 0.1205 - val_top5_accuracy: 0.1658\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.07750\n",
      "Epoch 17/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.6236 - accuracy: 0.0638 - top3_accuracy: 0.1417 - top5_accuracy: 0.1986 - val_loss: 4.4607 - val_accuracy: 0.0824 - val_top3_accuracy: 0.1740 - val_top5_accuracy: 0.2367\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.07750 to 0.08240, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 18/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.6013 - accuracy: 0.0667 - top3_accuracy: 0.1470 - top5_accuracy: 0.2043 - val_loss: 4.3599 - val_accuracy: 0.0684 - val_top3_accuracy: 0.1494 - val_top5_accuracy: 0.2067\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.08240\n",
      "Epoch 19/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.5857 - accuracy: 0.0671 - top3_accuracy: 0.1481 - top5_accuracy: 0.2071 - val_loss: 4.5720 - val_accuracy: 0.0882 - val_top3_accuracy: 0.1871 - val_top5_accuracy: 0.2528\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.08240 to 0.08820, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 20/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.5710 - accuracy: 0.0702 - top3_accuracy: 0.1535 - top5_accuracy: 0.2130 - val_loss: 4.3257 - val_accuracy: 0.0848 - val_top3_accuracy: 0.1756 - val_top5_accuracy: 0.2402\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.08820\n",
      "Epoch 21/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.5495 - accuracy: 0.0717 - top3_accuracy: 0.1570 - top5_accuracy: 0.2171 - val_loss: 4.0638 - val_accuracy: 0.0643 - val_top3_accuracy: 0.1422 - val_top5_accuracy: 0.1954\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.08820\n",
      "Epoch 22/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.5347 - accuracy: 0.0736 - top3_accuracy: 0.1601 - top5_accuracy: 0.2214 - val_loss: 4.3288 - val_accuracy: 0.0769 - val_top3_accuracy: 0.1645 - val_top5_accuracy: 0.2276\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.08820\n",
      "Epoch 23/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.5290 - accuracy: 0.0751 - top3_accuracy: 0.1615 - top5_accuracy: 0.2220 - val_loss: 4.0212 - val_accuracy: 0.1060 - val_top3_accuracy: 0.2062 - val_top5_accuracy: 0.2822\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.08820 to 0.10600, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 24/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.5130 - accuracy: 0.0768 - top3_accuracy: 0.1658 - top5_accuracy: 0.2265 - val_loss: 4.3380 - val_accuracy: 0.0981 - val_top3_accuracy: 0.2073 - val_top5_accuracy: 0.2802\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.10600\n",
      "Epoch 25/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.4980 - accuracy: 0.0772 - top3_accuracy: 0.1680 - top5_accuracy: 0.2304 - val_loss: 3.6472 - val_accuracy: 0.0935 - val_top3_accuracy: 0.1908 - val_top5_accuracy: 0.2543\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.10600\n",
      "Epoch 26/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.4868 - accuracy: 0.0785 - top3_accuracy: 0.1676 - top5_accuracy: 0.2305 - val_loss: 4.4207 - val_accuracy: 0.1050 - val_top3_accuracy: 0.2105 - val_top5_accuracy: 0.2858\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.10600\n",
      "Epoch 27/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.4754 - accuracy: 0.0809 - top3_accuracy: 0.1718 - top5_accuracy: 0.2367 - val_loss: 4.2530 - val_accuracy: 0.1101 - val_top3_accuracy: 0.2227 - val_top5_accuracy: 0.2955\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.10600 to 0.11010, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 28/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.4624 - accuracy: 0.0822 - top3_accuracy: 0.1750 - top5_accuracy: 0.2380 - val_loss: 4.8976 - val_accuracy: 0.0961 - val_top3_accuracy: 0.1933 - val_top5_accuracy: 0.2664\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.11010\n",
      "Epoch 29/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.4562 - accuracy: 0.0838 - top3_accuracy: 0.1765 - top5_accuracy: 0.2413 - val_loss: 4.3319 - val_accuracy: 0.1129 - val_top3_accuracy: 0.2205 - val_top5_accuracy: 0.2944\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.11010 to 0.11290, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 30/300\n",
      "3125/3125 [==============================] - 186s 60ms/step - loss: 4.4469 - accuracy: 0.0851 - top3_accuracy: 0.1778 - top5_accuracy: 0.2436 - val_loss: 4.6478 - val_accuracy: 0.1168 - val_top3_accuracy: 0.2329 - val_top5_accuracy: 0.3037\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.11290 to 0.11680, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 31/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.4336 - accuracy: 0.0860 - top3_accuracy: 0.1831 - top5_accuracy: 0.2488 - val_loss: 4.5977 - val_accuracy: 0.1132 - val_top3_accuracy: 0.2263 - val_top5_accuracy: 0.2994\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.11680\n",
      "Epoch 32/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.4258 - accuracy: 0.0875 - top3_accuracy: 0.1835 - top5_accuracy: 0.2483 - val_loss: 4.0021 - val_accuracy: 0.1210 - val_top3_accuracy: 0.2378 - val_top5_accuracy: 0.3112\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.11680 to 0.12100, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 33/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.4148 - accuracy: 0.0875 - top3_accuracy: 0.1838 - top5_accuracy: 0.2497 - val_loss: 3.7235 - val_accuracy: 0.1166 - val_top3_accuracy: 0.2279 - val_top5_accuracy: 0.3067\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.12100\n",
      "Epoch 34/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.4103 - accuracy: 0.0892 - top3_accuracy: 0.1855 - top5_accuracy: 0.2513 - val_loss: 5.1066 - val_accuracy: 0.0970 - val_top3_accuracy: 0.2028 - val_top5_accuracy: 0.2737\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.12100\n",
      "Epoch 35/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.3931 - accuracy: 0.0917 - top3_accuracy: 0.1906 - top5_accuracy: 0.2576 - val_loss: 4.0537 - val_accuracy: 0.1154 - val_top3_accuracy: 0.2365 - val_top5_accuracy: 0.3129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.12100\n",
      "Epoch 36/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.3865 - accuracy: 0.0940 - top3_accuracy: 0.1929 - top5_accuracy: 0.2595 - val_loss: 3.6747 - val_accuracy: 0.1167 - val_top3_accuracy: 0.2348 - val_top5_accuracy: 0.3104\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.12100\n",
      "Epoch 37/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.3792 - accuracy: 0.0935 - top3_accuracy: 0.1925 - top5_accuracy: 0.2597 - val_loss: 3.7443 - val_accuracy: 0.1195 - val_top3_accuracy: 0.2346 - val_top5_accuracy: 0.3115\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.12100\n",
      "Epoch 38/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.3696 - accuracy: 0.0945 - top3_accuracy: 0.1939 - top5_accuracy: 0.2627 - val_loss: 3.4354 - val_accuracy: 0.1252 - val_top3_accuracy: 0.2500 - val_top5_accuracy: 0.3292\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.12100 to 0.12520, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 39/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.3601 - accuracy: 0.0953 - top3_accuracy: 0.1963 - top5_accuracy: 0.2640 - val_loss: 4.2509 - val_accuracy: 0.1047 - val_top3_accuracy: 0.2124 - val_top5_accuracy: 0.2814\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.12520\n",
      "Epoch 40/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.3553 - accuracy: 0.0961 - top3_accuracy: 0.1968 - top5_accuracy: 0.2656 - val_loss: 3.6317 - val_accuracy: 0.1249 - val_top3_accuracy: 0.2462 - val_top5_accuracy: 0.3260\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.12520\n",
      "Epoch 41/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.3483 - accuracy: 0.0976 - top3_accuracy: 0.1983 - top5_accuracy: 0.2665 - val_loss: 3.6167 - val_accuracy: 0.1365 - val_top3_accuracy: 0.2615 - val_top5_accuracy: 0.3422\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.12520 to 0.13650, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 42/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.3363 - accuracy: 0.1008 - top3_accuracy: 0.2042 - top5_accuracy: 0.2732 - val_loss: 4.8331 - val_accuracy: 0.1301 - val_top3_accuracy: 0.2489 - val_top5_accuracy: 0.3262\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.13650\n",
      "Epoch 43/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.3292 - accuracy: 0.1010 - top3_accuracy: 0.2053 - top5_accuracy: 0.2736 - val_loss: 4.1810 - val_accuracy: 0.1332 - val_top3_accuracy: 0.2562 - val_top5_accuracy: 0.3350\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.13650\n",
      "Epoch 44/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.3214 - accuracy: 0.1007 - top3_accuracy: 0.2041 - top5_accuracy: 0.2742 - val_loss: 4.2150 - val_accuracy: 0.1377 - val_top3_accuracy: 0.2668 - val_top5_accuracy: 0.3466\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.13650 to 0.13770, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 45/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.3180 - accuracy: 0.1014 - top3_accuracy: 0.2053 - top5_accuracy: 0.2742 - val_loss: 4.9598 - val_accuracy: 0.1389 - val_top3_accuracy: 0.2630 - val_top5_accuracy: 0.3450\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.13770 to 0.13890, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 46/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.3123 - accuracy: 0.1013 - top3_accuracy: 0.2072 - top5_accuracy: 0.2767 - val_loss: 4.2415 - val_accuracy: 0.1376 - val_top3_accuracy: 0.2594 - val_top5_accuracy: 0.3361\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.13890\n",
      "Epoch 47/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.3049 - accuracy: 0.1032 - top3_accuracy: 0.2086 - top5_accuracy: 0.2791 - val_loss: 3.9958 - val_accuracy: 0.1380 - val_top3_accuracy: 0.2598 - val_top5_accuracy: 0.3372\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.13890\n",
      "Epoch 48/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.2996 - accuracy: 0.1044 - top3_accuracy: 0.2113 - top5_accuracy: 0.2815 - val_loss: 3.8169 - val_accuracy: 0.1225 - val_top3_accuracy: 0.2359 - val_top5_accuracy: 0.3101\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.13890\n",
      "Epoch 49/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.2861 - accuracy: 0.1059 - top3_accuracy: 0.2131 - top5_accuracy: 0.2829 - val_loss: 4.3348 - val_accuracy: 0.1429 - val_top3_accuracy: 0.2709 - val_top5_accuracy: 0.3521\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.13890 to 0.14290, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 50/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2795 - accuracy: 0.1046 - top3_accuracy: 0.2139 - top5_accuracy: 0.2844 - val_loss: 3.4503 - val_accuracy: 0.1435 - val_top3_accuracy: 0.2739 - val_top5_accuracy: 0.3516\n",
      "\n",
      "Epoch 00050: val_accuracy improved from 0.14290 to 0.14350, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 51/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2728 - accuracy: 0.1071 - top3_accuracy: 0.2144 - top5_accuracy: 0.2857 - val_loss: 3.9176 - val_accuracy: 0.1348 - val_top3_accuracy: 0.2580 - val_top5_accuracy: 0.3378\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.14350\n",
      "Epoch 52/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.2692 - accuracy: 0.1094 - top3_accuracy: 0.2169 - top5_accuracy: 0.2866 - val_loss: 3.7543 - val_accuracy: 0.1450 - val_top3_accuracy: 0.2726 - val_top5_accuracy: 0.3509\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.14350 to 0.14500, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 53/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.2624 - accuracy: 0.1089 - top3_accuracy: 0.2172 - top5_accuracy: 0.2884 - val_loss: 3.5456 - val_accuracy: 0.1423 - val_top3_accuracy: 0.2695 - val_top5_accuracy: 0.3463\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.14500\n",
      "Epoch 54/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2470 - accuracy: 0.1099 - top3_accuracy: 0.2211 - top5_accuracy: 0.2934 - val_loss: 4.4218 - val_accuracy: 0.1478 - val_top3_accuracy: 0.2739 - val_top5_accuracy: 0.3526\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.14500 to 0.14780, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 55/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2504 - accuracy: 0.1100 - top3_accuracy: 0.2202 - top5_accuracy: 0.2914 - val_loss: 4.0787 - val_accuracy: 0.1177 - val_top3_accuracy: 0.2259 - val_top5_accuracy: 0.2990\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.14780\n",
      "Epoch 56/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2460 - accuracy: 0.1107 - top3_accuracy: 0.2218 - top5_accuracy: 0.2940 - val_loss: 4.1126 - val_accuracy: 0.1276 - val_top3_accuracy: 0.2500 - val_top5_accuracy: 0.3270\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.14780\n",
      "Epoch 57/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2414 - accuracy: 0.1125 - top3_accuracy: 0.2212 - top5_accuracy: 0.2937 - val_loss: 4.0879 - val_accuracy: 0.1493 - val_top3_accuracy: 0.2794 - val_top5_accuracy: 0.3543\n",
      "\n",
      "Epoch 00057: val_accuracy improved from 0.14780 to 0.14930, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 58/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2330 - accuracy: 0.1135 - top3_accuracy: 0.2252 - top5_accuracy: 0.2975 - val_loss: 3.4527 - val_accuracy: 0.1432 - val_top3_accuracy: 0.2689 - val_top5_accuracy: 0.3486\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.14930\n",
      "Epoch 59/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2235 - accuracy: 0.1137 - top3_accuracy: 0.2274 - top5_accuracy: 0.2999 - val_loss: 4.1831 - val_accuracy: 0.1559 - val_top3_accuracy: 0.2953 - val_top5_accuracy: 0.3751\n",
      "\n",
      "Epoch 00059: val_accuracy improved from 0.14930 to 0.15590, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 60/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2288 - accuracy: 0.1143 - top3_accuracy: 0.2263 - top5_accuracy: 0.2993 - val_loss: 3.3172 - val_accuracy: 0.1483 - val_top3_accuracy: 0.2803 - val_top5_accuracy: 0.3577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.15590\n",
      "Epoch 61/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2145 - accuracy: 0.1151 - top3_accuracy: 0.2288 - top5_accuracy: 0.3004 - val_loss: 4.3191 - val_accuracy: 0.1448 - val_top3_accuracy: 0.2743 - val_top5_accuracy: 0.3517\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.15590\n",
      "Epoch 62/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2114 - accuracy: 0.1155 - top3_accuracy: 0.2307 - top5_accuracy: 0.3034 - val_loss: 3.5692 - val_accuracy: 0.1547 - val_top3_accuracy: 0.2862 - val_top5_accuracy: 0.3656\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.15590\n",
      "Epoch 63/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2049 - accuracy: 0.1165 - top3_accuracy: 0.2304 - top5_accuracy: 0.3032 - val_loss: 4.3177 - val_accuracy: 0.1445 - val_top3_accuracy: 0.2770 - val_top5_accuracy: 0.3579\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.15590\n",
      "Epoch 64/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1969 - accuracy: 0.1181 - top3_accuracy: 0.2322 - top5_accuracy: 0.3044 - val_loss: 2.8828 - val_accuracy: 0.1586 - val_top3_accuracy: 0.2952 - val_top5_accuracy: 0.3842\n",
      "\n",
      "Epoch 00064: val_accuracy improved from 0.15590 to 0.15860, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 65/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.2019 - accuracy: 0.1164 - top3_accuracy: 0.2313 - top5_accuracy: 0.3049 - val_loss: 3.9929 - val_accuracy: 0.1660 - val_top3_accuracy: 0.3003 - val_top5_accuracy: 0.3813\n",
      "\n",
      "Epoch 00065: val_accuracy improved from 0.15860 to 0.16600, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 66/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1964 - accuracy: 0.1187 - top3_accuracy: 0.2318 - top5_accuracy: 0.3053 - val_loss: 3.9135 - val_accuracy: 0.1517 - val_top3_accuracy: 0.2974 - val_top5_accuracy: 0.3783\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.16600\n",
      "Epoch 67/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.1874 - accuracy: 0.1196 - top3_accuracy: 0.2339 - top5_accuracy: 0.3072 - val_loss: 3.9616 - val_accuracy: 0.1603 - val_top3_accuracy: 0.2934 - val_top5_accuracy: 0.3747\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.16600\n",
      "Epoch 68/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.1836 - accuracy: 0.1195 - top3_accuracy: 0.2344 - top5_accuracy: 0.3082 - val_loss: 4.3145 - val_accuracy: 0.1678 - val_top3_accuracy: 0.3101 - val_top5_accuracy: 0.3892\n",
      "\n",
      "Epoch 00068: val_accuracy improved from 0.16600 to 0.16780, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 69/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.1762 - accuracy: 0.1203 - top3_accuracy: 0.2357 - top5_accuracy: 0.3095 - val_loss: 3.6502 - val_accuracy: 0.1606 - val_top3_accuracy: 0.2991 - val_top5_accuracy: 0.3790\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.16780\n",
      "Epoch 70/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.1795 - accuracy: 0.1211 - top3_accuracy: 0.2350 - top5_accuracy: 0.3086 - val_loss: 4.3701 - val_accuracy: 0.1646 - val_top3_accuracy: 0.3011 - val_top5_accuracy: 0.3842\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.16780\n",
      "Epoch 71/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1710 - accuracy: 0.1226 - top3_accuracy: 0.2397 - top5_accuracy: 0.3131 - val_loss: 4.1349 - val_accuracy: 0.1706 - val_top3_accuracy: 0.3109 - val_top5_accuracy: 0.3935\n",
      "\n",
      "Epoch 00071: val_accuracy improved from 0.16780 to 0.17060, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 72/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1641 - accuracy: 0.1230 - top3_accuracy: 0.2409 - top5_accuracy: 0.3148 - val_loss: 3.4349 - val_accuracy: 0.1587 - val_top3_accuracy: 0.2961 - val_top5_accuracy: 0.3831\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.17060\n",
      "Epoch 73/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1568 - accuracy: 0.1234 - top3_accuracy: 0.2411 - top5_accuracy: 0.3149 - val_loss: 4.2282 - val_accuracy: 0.1648 - val_top3_accuracy: 0.2952 - val_top5_accuracy: 0.3777\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.17060\n",
      "Epoch 74/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1559 - accuracy: 0.1234 - top3_accuracy: 0.2404 - top5_accuracy: 0.3160 - val_loss: 3.6123 - val_accuracy: 0.1685 - val_top3_accuracy: 0.3092 - val_top5_accuracy: 0.3924\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.17060\n",
      "Epoch 75/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1472 - accuracy: 0.1246 - top3_accuracy: 0.2433 - top5_accuracy: 0.3185 - val_loss: 3.8616 - val_accuracy: 0.1653 - val_top3_accuracy: 0.3074 - val_top5_accuracy: 0.3921\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.17060\n",
      "Epoch 76/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1418 - accuracy: 0.1255 - top3_accuracy: 0.2440 - top5_accuracy: 0.3194 - val_loss: 3.3508 - val_accuracy: 0.1702 - val_top3_accuracy: 0.3146 - val_top5_accuracy: 0.4050\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.17060\n",
      "Epoch 77/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.1387 - accuracy: 0.1251 - top3_accuracy: 0.2449 - top5_accuracy: 0.3198 - val_loss: 3.3238 - val_accuracy: 0.1696 - val_top3_accuracy: 0.3043 - val_top5_accuracy: 0.3796\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.17060\n",
      "Epoch 78/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1363 - accuracy: 0.1272 - top3_accuracy: 0.2458 - top5_accuracy: 0.3191 - val_loss: 3.7688 - val_accuracy: 0.1710 - val_top3_accuracy: 0.3155 - val_top5_accuracy: 0.3956\n",
      "\n",
      "Epoch 00078: val_accuracy improved from 0.17060 to 0.17100, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 79/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1422 - accuracy: 0.1255 - top3_accuracy: 0.2437 - top5_accuracy: 0.3192 - val_loss: 4.3957 - val_accuracy: 0.1748 - val_top3_accuracy: 0.3206 - val_top5_accuracy: 0.4017\n",
      "\n",
      "Epoch 00079: val_accuracy improved from 0.17100 to 0.17480, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 80/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1278 - accuracy: 0.1284 - top3_accuracy: 0.2470 - top5_accuracy: 0.3217 - val_loss: 4.1233 - val_accuracy: 0.1715 - val_top3_accuracy: 0.3181 - val_top5_accuracy: 0.4033\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.17480\n",
      "Epoch 81/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.1191 - accuracy: 0.1299 - top3_accuracy: 0.2501 - top5_accuracy: 0.3260 - val_loss: 3.8897 - val_accuracy: 0.1770 - val_top3_accuracy: 0.3167 - val_top5_accuracy: 0.4016\n",
      "\n",
      "Epoch 00081: val_accuracy improved from 0.17480 to 0.17700, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 82/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1211 - accuracy: 0.1277 - top3_accuracy: 0.2482 - top5_accuracy: 0.3238 - val_loss: 4.0850 - val_accuracy: 0.1797 - val_top3_accuracy: 0.3223 - val_top5_accuracy: 0.4080\n",
      "\n",
      "Epoch 00082: val_accuracy improved from 0.17700 to 0.17970, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 83/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1155 - accuracy: 0.1304 - top3_accuracy: 0.2514 - top5_accuracy: 0.3256 - val_loss: 3.1987 - val_accuracy: 0.1794 - val_top3_accuracy: 0.3248 - val_top5_accuracy: 0.4062\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.17970\n",
      "Epoch 84/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1152 - accuracy: 0.1294 - top3_accuracy: 0.2492 - top5_accuracy: 0.3254 - val_loss: 3.3014 - val_accuracy: 0.1736 - val_top3_accuracy: 0.3149 - val_top5_accuracy: 0.4004\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.17970\n",
      "Epoch 85/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.1104 - accuracy: 0.1308 - top3_accuracy: 0.2532 - top5_accuracy: 0.3269 - val_loss: 3.7149 - val_accuracy: 0.1819 - val_top3_accuracy: 0.3282 - val_top5_accuracy: 0.4126\n",
      "\n",
      "Epoch 00085: val_accuracy improved from 0.17970 to 0.18190, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.1089 - accuracy: 0.1312 - top3_accuracy: 0.2522 - top5_accuracy: 0.3269 - val_loss: 3.9190 - val_accuracy: 0.1809 - val_top3_accuracy: 0.3308 - val_top5_accuracy: 0.4169\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.18190\n",
      "Epoch 87/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0998 - accuracy: 0.1304 - top3_accuracy: 0.2535 - top5_accuracy: 0.3303 - val_loss: 3.7944 - val_accuracy: 0.1823 - val_top3_accuracy: 0.3262 - val_top5_accuracy: 0.4076\n",
      "\n",
      "Epoch 00087: val_accuracy improved from 0.18190 to 0.18230, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 88/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0974 - accuracy: 0.1320 - top3_accuracy: 0.2533 - top5_accuracy: 0.3282 - val_loss: 3.6590 - val_accuracy: 0.1809 - val_top3_accuracy: 0.3295 - val_top5_accuracy: 0.4139\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.18230\n",
      "Epoch 89/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0937 - accuracy: 0.1325 - top3_accuracy: 0.2533 - top5_accuracy: 0.3293 - val_loss: 3.6161 - val_accuracy: 0.1843 - val_top3_accuracy: 0.3293 - val_top5_accuracy: 0.4132\n",
      "\n",
      "Epoch 00089: val_accuracy improved from 0.18230 to 0.18430, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 90/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0867 - accuracy: 0.1333 - top3_accuracy: 0.2562 - top5_accuracy: 0.3334 - val_loss: 4.1011 - val_accuracy: 0.1537 - val_top3_accuracy: 0.2770 - val_top5_accuracy: 0.3504\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.18430\n",
      "Epoch 91/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0951 - accuracy: 0.1330 - top3_accuracy: 0.2542 - top5_accuracy: 0.3289 - val_loss: 3.8902 - val_accuracy: 0.1845 - val_top3_accuracy: 0.3270 - val_top5_accuracy: 0.4128\n",
      "\n",
      "Epoch 00091: val_accuracy improved from 0.18430 to 0.18450, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 92/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0818 - accuracy: 0.1342 - top3_accuracy: 0.2581 - top5_accuracy: 0.3339 - val_loss: 3.9134 - val_accuracy: 0.1892 - val_top3_accuracy: 0.3323 - val_top5_accuracy: 0.4174\n",
      "\n",
      "Epoch 00092: val_accuracy improved from 0.18450 to 0.18920, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 93/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0828 - accuracy: 0.1347 - top3_accuracy: 0.2561 - top5_accuracy: 0.3331 - val_loss: 3.6465 - val_accuracy: 0.1872 - val_top3_accuracy: 0.3389 - val_top5_accuracy: 0.4248\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.18920\n",
      "Epoch 94/300\n",
      "3125/3125 [==============================] - 186s 60ms/step - loss: 4.0747 - accuracy: 0.1355 - top3_accuracy: 0.2586 - top5_accuracy: 0.3352 - val_loss: 3.7240 - val_accuracy: 0.1858 - val_top3_accuracy: 0.3267 - val_top5_accuracy: 0.4087\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.18920\n",
      "Epoch 95/300\n",
      "3125/3125 [==============================] - 186s 60ms/step - loss: 4.0710 - accuracy: 0.1355 - top3_accuracy: 0.2602 - top5_accuracy: 0.3355 - val_loss: 4.0750 - val_accuracy: 0.1930 - val_top3_accuracy: 0.3390 - val_top5_accuracy: 0.4280\n",
      "\n",
      "Epoch 00095: val_accuracy improved from 0.18920 to 0.19300, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 96/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0676 - accuracy: 0.1353 - top3_accuracy: 0.2603 - top5_accuracy: 0.3381 - val_loss: 3.5447 - val_accuracy: 0.1850 - val_top3_accuracy: 0.3294 - val_top5_accuracy: 0.4157\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.19300\n",
      "Epoch 97/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.0659 - accuracy: 0.1365 - top3_accuracy: 0.2616 - top5_accuracy: 0.3392 - val_loss: 3.9166 - val_accuracy: 0.1793 - val_top3_accuracy: 0.3193 - val_top5_accuracy: 0.3999\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.19300\n",
      "Epoch 98/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0637 - accuracy: 0.1378 - top3_accuracy: 0.2622 - top5_accuracy: 0.3379 - val_loss: 3.8989 - val_accuracy: 0.1905 - val_top3_accuracy: 0.3393 - val_top5_accuracy: 0.4200\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.19300\n",
      "Epoch 99/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0623 - accuracy: 0.1380 - top3_accuracy: 0.2614 - top5_accuracy: 0.3377 - val_loss: 4.3812 - val_accuracy: 0.1910 - val_top3_accuracy: 0.3366 - val_top5_accuracy: 0.4219\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.19300\n",
      "Epoch 100/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.0522 - accuracy: 0.1385 - top3_accuracy: 0.2645 - top5_accuracy: 0.3413 - val_loss: 3.6145 - val_accuracy: 0.1886 - val_top3_accuracy: 0.3398 - val_top5_accuracy: 0.4227\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.19300\n",
      "Epoch 101/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.0530 - accuracy: 0.1392 - top3_accuracy: 0.2649 - top5_accuracy: 0.3409 - val_loss: 3.9241 - val_accuracy: 0.1845 - val_top3_accuracy: 0.3314 - val_top5_accuracy: 0.4138\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.19300\n",
      "Epoch 102/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.0510 - accuracy: 0.1391 - top3_accuracy: 0.2638 - top5_accuracy: 0.3417 - val_loss: 4.1350 - val_accuracy: 0.1898 - val_top3_accuracy: 0.3456 - val_top5_accuracy: 0.4325\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.19300\n",
      "Epoch 103/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0441 - accuracy: 0.1392 - top3_accuracy: 0.2656 - top5_accuracy: 0.3431 - val_loss: 3.3845 - val_accuracy: 0.1958 - val_top3_accuracy: 0.3468 - val_top5_accuracy: 0.4270\n",
      "\n",
      "Epoch 00103: val_accuracy improved from 0.19300 to 0.19580, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 104/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0367 - accuracy: 0.1408 - top3_accuracy: 0.2677 - top5_accuracy: 0.3457 - val_loss: 4.4066 - val_accuracy: 0.1928 - val_top3_accuracy: 0.3490 - val_top5_accuracy: 0.4327\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.19580\n",
      "Epoch 105/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0390 - accuracy: 0.1406 - top3_accuracy: 0.2672 - top5_accuracy: 0.3429 - val_loss: 4.3104 - val_accuracy: 0.1935 - val_top3_accuracy: 0.3415 - val_top5_accuracy: 0.4290\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.19580\n",
      "Epoch 106/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0361 - accuracy: 0.1412 - top3_accuracy: 0.2669 - top5_accuracy: 0.3439 - val_loss: 3.5529 - val_accuracy: 0.1877 - val_top3_accuracy: 0.3392 - val_top5_accuracy: 0.4261\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.19580\n",
      "Epoch 107/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0257 - accuracy: 0.1416 - top3_accuracy: 0.2685 - top5_accuracy: 0.3477 - val_loss: 3.9709 - val_accuracy: 0.1979 - val_top3_accuracy: 0.3457 - val_top5_accuracy: 0.4331\n",
      "\n",
      "Epoch 00107: val_accuracy improved from 0.19580 to 0.19790, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 108/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0275 - accuracy: 0.1436 - top3_accuracy: 0.2683 - top5_accuracy: 0.3467 - val_loss: 4.3210 - val_accuracy: 0.1940 - val_top3_accuracy: 0.3449 - val_top5_accuracy: 0.4313\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.19790\n",
      "Epoch 109/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0298 - accuracy: 0.1429 - top3_accuracy: 0.2720 - top5_accuracy: 0.3478 - val_loss: 3.7234 - val_accuracy: 0.1808 - val_top3_accuracy: 0.3266 - val_top5_accuracy: 0.4091\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.19790\n",
      "Epoch 110/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0133 - accuracy: 0.1447 - top3_accuracy: 0.2717 - top5_accuracy: 0.3491 - val_loss: 2.8309 - val_accuracy: 0.1991 - val_top3_accuracy: 0.3518 - val_top5_accuracy: 0.4376\n",
      "\n",
      "Epoch 00110: val_accuracy improved from 0.19790 to 0.19910, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.0205 - accuracy: 0.1438 - top3_accuracy: 0.2698 - top5_accuracy: 0.3474 - val_loss: 3.1284 - val_accuracy: 0.1962 - val_top3_accuracy: 0.3447 - val_top5_accuracy: 0.4315\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.19910\n",
      "Epoch 112/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 4.0172 - accuracy: 0.1440 - top3_accuracy: 0.2711 - top5_accuracy: 0.3489 - val_loss: 3.9788 - val_accuracy: 0.2004 - val_top3_accuracy: 0.3532 - val_top5_accuracy: 0.4374\n",
      "\n",
      "Epoch 00112: val_accuracy improved from 0.19910 to 0.20040, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 113/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0165 - accuracy: 0.1449 - top3_accuracy: 0.2722 - top5_accuracy: 0.3492 - val_loss: 3.3781 - val_accuracy: 0.1972 - val_top3_accuracy: 0.3550 - val_top5_accuracy: 0.4413\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.20040\n",
      "Epoch 114/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0081 - accuracy: 0.1452 - top3_accuracy: 0.2736 - top5_accuracy: 0.3512 - val_loss: 3.2461 - val_accuracy: 0.2022 - val_top3_accuracy: 0.3449 - val_top5_accuracy: 0.4276\n",
      "\n",
      "Epoch 00114: val_accuracy improved from 0.20040 to 0.20220, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 115/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0042 - accuracy: 0.1467 - top3_accuracy: 0.2738 - top5_accuracy: 0.3523 - val_loss: 4.3385 - val_accuracy: 0.1942 - val_top3_accuracy: 0.3434 - val_top5_accuracy: 0.4250\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.20220\n",
      "Epoch 116/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0110 - accuracy: 0.1453 - top3_accuracy: 0.2722 - top5_accuracy: 0.3505 - val_loss: 4.0051 - val_accuracy: 0.2006 - val_top3_accuracy: 0.3550 - val_top5_accuracy: 0.4404\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.20220\n",
      "Epoch 117/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9966 - accuracy: 0.1452 - top3_accuracy: 0.2757 - top5_accuracy: 0.3553 - val_loss: 4.0530 - val_accuracy: 0.1767 - val_top3_accuracy: 0.3172 - val_top5_accuracy: 0.4046\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.20220\n",
      "Epoch 118/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9969 - accuracy: 0.1457 - top3_accuracy: 0.2749 - top5_accuracy: 0.3545 - val_loss: 3.5306 - val_accuracy: 0.2017 - val_top3_accuracy: 0.3576 - val_top5_accuracy: 0.4418\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.20220\n",
      "Epoch 119/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9972 - accuracy: 0.1464 - top3_accuracy: 0.2765 - top5_accuracy: 0.3560 - val_loss: 3.6481 - val_accuracy: 0.2021 - val_top3_accuracy: 0.3563 - val_top5_accuracy: 0.4366\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.20220\n",
      "Epoch 120/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9961 - accuracy: 0.1459 - top3_accuracy: 0.2785 - top5_accuracy: 0.3552 - val_loss: 4.3492 - val_accuracy: 0.2054 - val_top3_accuracy: 0.3670 - val_top5_accuracy: 0.4479\n",
      "\n",
      "Epoch 00120: val_accuracy improved from 0.20220 to 0.20540, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 121/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 4.0008 - accuracy: 0.1462 - top3_accuracy: 0.2752 - top5_accuracy: 0.3523 - val_loss: 3.2972 - val_accuracy: 0.2064 - val_top3_accuracy: 0.3626 - val_top5_accuracy: 0.4476\n",
      "\n",
      "Epoch 00121: val_accuracy improved from 0.20540 to 0.20640, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 122/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9847 - accuracy: 0.1483 - top3_accuracy: 0.2784 - top5_accuracy: 0.3565 - val_loss: 4.2950 - val_accuracy: 0.2025 - val_top3_accuracy: 0.3538 - val_top5_accuracy: 0.4393\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.20640\n",
      "Epoch 123/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9864 - accuracy: 0.1495 - top3_accuracy: 0.2800 - top5_accuracy: 0.3596 - val_loss: 4.2348 - val_accuracy: 0.1844 - val_top3_accuracy: 0.3283 - val_top5_accuracy: 0.4158\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.20640\n",
      "Epoch 124/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9728 - accuracy: 0.1513 - top3_accuracy: 0.2802 - top5_accuracy: 0.3593 - val_loss: 3.2772 - val_accuracy: 0.2073 - val_top3_accuracy: 0.3673 - val_top5_accuracy: 0.4500\n",
      "\n",
      "Epoch 00124: val_accuracy improved from 0.20640 to 0.20730, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 125/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9801 - accuracy: 0.1487 - top3_accuracy: 0.2796 - top5_accuracy: 0.3589 - val_loss: 3.8685 - val_accuracy: 0.2021 - val_top3_accuracy: 0.3551 - val_top5_accuracy: 0.4445\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.20730\n",
      "Epoch 126/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9795 - accuracy: 0.1506 - top3_accuracy: 0.2809 - top5_accuracy: 0.3584 - val_loss: 3.5333 - val_accuracy: 0.2092 - val_top3_accuracy: 0.3634 - val_top5_accuracy: 0.4458\n",
      "\n",
      "Epoch 00126: val_accuracy improved from 0.20730 to 0.20920, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 127/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9661 - accuracy: 0.1517 - top3_accuracy: 0.2824 - top5_accuracy: 0.3627 - val_loss: 4.0050 - val_accuracy: 0.1994 - val_top3_accuracy: 0.3561 - val_top5_accuracy: 0.4394\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.20920\n",
      "Epoch 128/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9717 - accuracy: 0.1516 - top3_accuracy: 0.2822 - top5_accuracy: 0.3614 - val_loss: 3.6979 - val_accuracy: 0.2062 - val_top3_accuracy: 0.3639 - val_top5_accuracy: 0.4455\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.20920\n",
      "Epoch 129/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9767 - accuracy: 0.1505 - top3_accuracy: 0.2799 - top5_accuracy: 0.3595 - val_loss: 3.4843 - val_accuracy: 0.2109 - val_top3_accuracy: 0.3656 - val_top5_accuracy: 0.4521\n",
      "\n",
      "Epoch 00129: val_accuracy improved from 0.20920 to 0.21090, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 130/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9717 - accuracy: 0.1502 - top3_accuracy: 0.2808 - top5_accuracy: 0.3600 - val_loss: 3.6743 - val_accuracy: 0.2060 - val_top3_accuracy: 0.3613 - val_top5_accuracy: 0.4488\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.21090\n",
      "Epoch 131/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9703 - accuracy: 0.1511 - top3_accuracy: 0.2822 - top5_accuracy: 0.3620 - val_loss: 3.4385 - val_accuracy: 0.2093 - val_top3_accuracy: 0.3626 - val_top5_accuracy: 0.4476\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.21090\n",
      "Epoch 132/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9660 - accuracy: 0.1490 - top3_accuracy: 0.2812 - top5_accuracy: 0.3604 - val_loss: 3.4179 - val_accuracy: 0.2147 - val_top3_accuracy: 0.3715 - val_top5_accuracy: 0.4544\n",
      "\n",
      "Epoch 00132: val_accuracy improved from 0.21090 to 0.21470, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 133/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9619 - accuracy: 0.1532 - top3_accuracy: 0.2845 - top5_accuracy: 0.3627 - val_loss: 3.3651 - val_accuracy: 0.2109 - val_top3_accuracy: 0.3636 - val_top5_accuracy: 0.4485\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.21470\n",
      "Epoch 134/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9597 - accuracy: 0.1518 - top3_accuracy: 0.2835 - top5_accuracy: 0.3625 - val_loss: 4.3618 - val_accuracy: 0.2176 - val_top3_accuracy: 0.3603 - val_top5_accuracy: 0.4497\n",
      "\n",
      "Epoch 00134: val_accuracy improved from 0.21470 to 0.21760, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 135/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9547 - accuracy: 0.1544 - top3_accuracy: 0.2858 - top5_accuracy: 0.3652 - val_loss: 3.5486 - val_accuracy: 0.2154 - val_top3_accuracy: 0.3708 - val_top5_accuracy: 0.4539\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.21760\n",
      "Epoch 136/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9565 - accuracy: 0.1524 - top3_accuracy: 0.2833 - top5_accuracy: 0.3631 - val_loss: 3.1805 - val_accuracy: 0.2046 - val_top3_accuracy: 0.3619 - val_top5_accuracy: 0.4474\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.21760\n",
      "Epoch 137/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9519 - accuracy: 0.1513 - top3_accuracy: 0.2850 - top5_accuracy: 0.3646 - val_loss: 3.3969 - val_accuracy: 0.2199 - val_top3_accuracy: 0.3789 - val_top5_accuracy: 0.4655\n",
      "\n",
      "Epoch 00137: val_accuracy improved from 0.21760 to 0.21990, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 138/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9506 - accuracy: 0.1547 - top3_accuracy: 0.2863 - top5_accuracy: 0.3656 - val_loss: 3.8272 - val_accuracy: 0.2093 - val_top3_accuracy: 0.3676 - val_top5_accuracy: 0.4493\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.21990\n",
      "Epoch 139/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9489 - accuracy: 0.1539 - top3_accuracy: 0.2859 - top5_accuracy: 0.3659 - val_loss: 3.7577 - val_accuracy: 0.1999 - val_top3_accuracy: 0.3508 - val_top5_accuracy: 0.4397\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.21990\n",
      "Epoch 140/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9398 - accuracy: 0.1546 - top3_accuracy: 0.2896 - top5_accuracy: 0.3684 - val_loss: 3.2276 - val_accuracy: 0.2030 - val_top3_accuracy: 0.3609 - val_top5_accuracy: 0.4481\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.21990\n",
      "Epoch 141/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9411 - accuracy: 0.1544 - top3_accuracy: 0.2900 - top5_accuracy: 0.3681 - val_loss: 3.8234 - val_accuracy: 0.2117 - val_top3_accuracy: 0.3723 - val_top5_accuracy: 0.4547\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.21990\n",
      "Epoch 142/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9401 - accuracy: 0.1565 - top3_accuracy: 0.2885 - top5_accuracy: 0.3673 - val_loss: 3.0758 - val_accuracy: 0.1919 - val_top3_accuracy: 0.3471 - val_top5_accuracy: 0.4307\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.21990\n",
      "Epoch 143/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9369 - accuracy: 0.1552 - top3_accuracy: 0.2893 - top5_accuracy: 0.3697 - val_loss: 2.9173 - val_accuracy: 0.2211 - val_top3_accuracy: 0.3798 - val_top5_accuracy: 0.4667\n",
      "\n",
      "Epoch 00143: val_accuracy improved from 0.21990 to 0.22110, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 144/300\n",
      "3125/3125 [==============================] - 186s 60ms/step - loss: 3.9364 - accuracy: 0.1550 - top3_accuracy: 0.2901 - top5_accuracy: 0.3697 - val_loss: 4.2438 - val_accuracy: 0.2128 - val_top3_accuracy: 0.3726 - val_top5_accuracy: 0.4624\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.22110\n",
      "Epoch 145/300\n",
      "3125/3125 [==============================] - 186s 60ms/step - loss: 3.9375 - accuracy: 0.1552 - top3_accuracy: 0.2894 - top5_accuracy: 0.3689 - val_loss: 4.7765 - val_accuracy: 0.2176 - val_top3_accuracy: 0.3728 - val_top5_accuracy: 0.4601\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.22110\n",
      "Epoch 146/300\n",
      "3125/3125 [==============================] - 187s 60ms/step - loss: 3.9314 - accuracy: 0.1579 - top3_accuracy: 0.2897 - top5_accuracy: 0.3692 - val_loss: 2.9278 - val_accuracy: 0.2138 - val_top3_accuracy: 0.3803 - val_top5_accuracy: 0.4662\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.22110\n",
      "Epoch 147/300\n",
      "3125/3125 [==============================] - 186s 60ms/step - loss: 3.9323 - accuracy: 0.1575 - top3_accuracy: 0.2908 - top5_accuracy: 0.3697 - val_loss: 2.7643 - val_accuracy: 0.2179 - val_top3_accuracy: 0.3781 - val_top5_accuracy: 0.4617\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.22110\n",
      "Epoch 148/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9298 - accuracy: 0.1569 - top3_accuracy: 0.2892 - top5_accuracy: 0.3706 - val_loss: 3.6629 - val_accuracy: 0.1854 - val_top3_accuracy: 0.3303 - val_top5_accuracy: 0.4098\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.22110\n",
      "Epoch 149/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9247 - accuracy: 0.1557 - top3_accuracy: 0.2910 - top5_accuracy: 0.3699 - val_loss: 3.4371 - val_accuracy: 0.2215 - val_top3_accuracy: 0.3784 - val_top5_accuracy: 0.4637\n",
      "\n",
      "Epoch 00149: val_accuracy improved from 0.22110 to 0.22150, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 150/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9275 - accuracy: 0.1581 - top3_accuracy: 0.2932 - top5_accuracy: 0.3720 - val_loss: 3.4375 - val_accuracy: 0.2194 - val_top3_accuracy: 0.3739 - val_top5_accuracy: 0.4607\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.22150\n",
      "Epoch 151/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9196 - accuracy: 0.1572 - top3_accuracy: 0.2937 - top5_accuracy: 0.3742 - val_loss: 3.5543 - val_accuracy: 0.2241 - val_top3_accuracy: 0.3833 - val_top5_accuracy: 0.4688\n",
      "\n",
      "Epoch 00151: val_accuracy improved from 0.22150 to 0.22410, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 152/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9201 - accuracy: 0.1577 - top3_accuracy: 0.2916 - top5_accuracy: 0.3724 - val_loss: 3.6267 - val_accuracy: 0.2217 - val_top3_accuracy: 0.3781 - val_top5_accuracy: 0.4603\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.22410\n",
      "Epoch 153/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9115 - accuracy: 0.1597 - top3_accuracy: 0.2950 - top5_accuracy: 0.3749 - val_loss: 2.9116 - val_accuracy: 0.2148 - val_top3_accuracy: 0.3780 - val_top5_accuracy: 0.4679\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.22410\n",
      "Epoch 154/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9162 - accuracy: 0.1588 - top3_accuracy: 0.2941 - top5_accuracy: 0.3744 - val_loss: 3.8098 - val_accuracy: 0.2243 - val_top3_accuracy: 0.3807 - val_top5_accuracy: 0.4694\n",
      "\n",
      "Epoch 00154: val_accuracy improved from 0.22410 to 0.22430, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 155/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9128 - accuracy: 0.1596 - top3_accuracy: 0.2950 - top5_accuracy: 0.3750 - val_loss: 4.6278 - val_accuracy: 0.2083 - val_top3_accuracy: 0.3595 - val_top5_accuracy: 0.4442\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.22430\n",
      "Epoch 156/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9156 - accuracy: 0.1605 - top3_accuracy: 0.2967 - top5_accuracy: 0.3745 - val_loss: 3.3453 - val_accuracy: 0.2200 - val_top3_accuracy: 0.3798 - val_top5_accuracy: 0.4695\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.22430\n",
      "Epoch 157/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9097 - accuracy: 0.1600 - top3_accuracy: 0.2946 - top5_accuracy: 0.3742 - val_loss: 3.0624 - val_accuracy: 0.2222 - val_top3_accuracy: 0.3832 - val_top5_accuracy: 0.4669\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.22430\n",
      "Epoch 158/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.9075 - accuracy: 0.1628 - top3_accuracy: 0.2965 - top5_accuracy: 0.3744 - val_loss: 3.5105 - val_accuracy: 0.2226 - val_top3_accuracy: 0.3827 - val_top5_accuracy: 0.4688\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.22430\n",
      "Epoch 159/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9120 - accuracy: 0.1609 - top3_accuracy: 0.2941 - top5_accuracy: 0.3747 - val_loss: 2.9351 - val_accuracy: 0.2225 - val_top3_accuracy: 0.3857 - val_top5_accuracy: 0.4736\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.22430\n",
      "Epoch 160/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.9007 - accuracy: 0.1613 - top3_accuracy: 0.2967 - top5_accuracy: 0.3764 - val_loss: 3.7351 - val_accuracy: 0.2200 - val_top3_accuracy: 0.3803 - val_top5_accuracy: 0.4737\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.22430\n",
      "Epoch 161/300\n",
      "3125/3125 [==============================] - 186s 60ms/step - loss: 3.9006 - accuracy: 0.1613 - top3_accuracy: 0.2986 - top5_accuracy: 0.3784 - val_loss: 3.4057 - val_accuracy: 0.2214 - val_top3_accuracy: 0.3826 - val_top5_accuracy: 0.4657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.22430\n",
      "Epoch 162/300\n",
      "3125/3125 [==============================] - 186s 60ms/step - loss: 3.9036 - accuracy: 0.1613 - top3_accuracy: 0.2968 - top5_accuracy: 0.3768 - val_loss: 3.3817 - val_accuracy: 0.2227 - val_top3_accuracy: 0.3794 - val_top5_accuracy: 0.4671\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.22430\n",
      "Epoch 163/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8998 - accuracy: 0.1605 - top3_accuracy: 0.2965 - top5_accuracy: 0.3773 - val_loss: 3.6570 - val_accuracy: 0.2289 - val_top3_accuracy: 0.3888 - val_top5_accuracy: 0.4753\n",
      "\n",
      "Epoch 00163: val_accuracy improved from 0.22430 to 0.22890, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 164/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8948 - accuracy: 0.1615 - top3_accuracy: 0.2972 - top5_accuracy: 0.3771 - val_loss: 3.3263 - val_accuracy: 0.2239 - val_top3_accuracy: 0.3877 - val_top5_accuracy: 0.4715\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.22890\n",
      "Epoch 165/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8937 - accuracy: 0.1613 - top3_accuracy: 0.2984 - top5_accuracy: 0.3770 - val_loss: 3.6279 - val_accuracy: 0.2187 - val_top3_accuracy: 0.3826 - val_top5_accuracy: 0.4721\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.22890\n",
      "Epoch 166/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8945 - accuracy: 0.1615 - top3_accuracy: 0.2973 - top5_accuracy: 0.3778 - val_loss: 4.0256 - val_accuracy: 0.2243 - val_top3_accuracy: 0.3863 - val_top5_accuracy: 0.4669\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.22890\n",
      "Epoch 167/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8957 - accuracy: 0.1614 - top3_accuracy: 0.2975 - top5_accuracy: 0.3795 - val_loss: 3.7180 - val_accuracy: 0.2120 - val_top3_accuracy: 0.3723 - val_top5_accuracy: 0.4604\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.22890\n",
      "Epoch 168/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8846 - accuracy: 0.1631 - top3_accuracy: 0.2996 - top5_accuracy: 0.3808 - val_loss: 4.2082 - val_accuracy: 0.2268 - val_top3_accuracy: 0.3858 - val_top5_accuracy: 0.4728\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.22890\n",
      "Epoch 169/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8949 - accuracy: 0.1622 - top3_accuracy: 0.2988 - top5_accuracy: 0.3781 - val_loss: 3.8645 - val_accuracy: 0.2156 - val_top3_accuracy: 0.3689 - val_top5_accuracy: 0.4563\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.22890\n",
      "Epoch 170/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8912 - accuracy: 0.1628 - top3_accuracy: 0.2974 - top5_accuracy: 0.3784 - val_loss: 4.0771 - val_accuracy: 0.2205 - val_top3_accuracy: 0.3841 - val_top5_accuracy: 0.4711\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.22890\n",
      "Epoch 171/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8850 - accuracy: 0.1660 - top3_accuracy: 0.3009 - top5_accuracy: 0.3816 - val_loss: 3.6841 - val_accuracy: 0.2265 - val_top3_accuracy: 0.3850 - val_top5_accuracy: 0.4734\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.22890\n",
      "Epoch 172/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8805 - accuracy: 0.1642 - top3_accuracy: 0.3020 - top5_accuracy: 0.3821 - val_loss: 3.4324 - val_accuracy: 0.2098 - val_top3_accuracy: 0.3603 - val_top5_accuracy: 0.4443\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.22890\n",
      "Epoch 173/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8804 - accuracy: 0.1638 - top3_accuracy: 0.3008 - top5_accuracy: 0.3834 - val_loss: 3.8651 - val_accuracy: 0.2120 - val_top3_accuracy: 0.3681 - val_top5_accuracy: 0.4543\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.22890\n",
      "Epoch 174/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8775 - accuracy: 0.1653 - top3_accuracy: 0.3011 - top5_accuracy: 0.3831 - val_loss: 3.9411 - val_accuracy: 0.2238 - val_top3_accuracy: 0.3849 - val_top5_accuracy: 0.4709\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.22890\n",
      "Epoch 175/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8824 - accuracy: 0.1646 - top3_accuracy: 0.3000 - top5_accuracy: 0.3821 - val_loss: 3.5154 - val_accuracy: 0.2276 - val_top3_accuracy: 0.3906 - val_top5_accuracy: 0.4780\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.22890\n",
      "Epoch 176/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.8786 - accuracy: 0.1658 - top3_accuracy: 0.3025 - top5_accuracy: 0.3843 - val_loss: 3.6368 - val_accuracy: 0.2330 - val_top3_accuracy: 0.3928 - val_top5_accuracy: 0.4762\n",
      "\n",
      "Epoch 00176: val_accuracy improved from 0.22890 to 0.23300, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 177/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8720 - accuracy: 0.1649 - top3_accuracy: 0.3032 - top5_accuracy: 0.3847 - val_loss: 3.6511 - val_accuracy: 0.2303 - val_top3_accuracy: 0.3973 - val_top5_accuracy: 0.4796\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.23300\n",
      "Epoch 178/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8675 - accuracy: 0.1655 - top3_accuracy: 0.3043 - top5_accuracy: 0.3849 - val_loss: 3.8575 - val_accuracy: 0.2315 - val_top3_accuracy: 0.3799 - val_top5_accuracy: 0.4673\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.23300\n",
      "Epoch 179/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8731 - accuracy: 0.1645 - top3_accuracy: 0.3027 - top5_accuracy: 0.3839 - val_loss: 3.7185 - val_accuracy: 0.2272 - val_top3_accuracy: 0.3841 - val_top5_accuracy: 0.4732\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.23300\n",
      "Epoch 180/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.8690 - accuracy: 0.1664 - top3_accuracy: 0.3028 - top5_accuracy: 0.3843 - val_loss: 3.1369 - val_accuracy: 0.2190 - val_top3_accuracy: 0.3755 - val_top5_accuracy: 0.4592\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.23300\n",
      "Epoch 181/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.8625 - accuracy: 0.1662 - top3_accuracy: 0.3055 - top5_accuracy: 0.3862 - val_loss: 3.7055 - val_accuracy: 0.2327 - val_top3_accuracy: 0.3949 - val_top5_accuracy: 0.4786\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.23300\n",
      "Epoch 182/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8667 - accuracy: 0.1663 - top3_accuracy: 0.3040 - top5_accuracy: 0.3843 - val_loss: 4.0457 - val_accuracy: 0.2322 - val_top3_accuracy: 0.3931 - val_top5_accuracy: 0.4807\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.23300\n",
      "Epoch 183/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8710 - accuracy: 0.1657 - top3_accuracy: 0.3032 - top5_accuracy: 0.3851 - val_loss: 3.0212 - val_accuracy: 0.2283 - val_top3_accuracy: 0.3887 - val_top5_accuracy: 0.4756\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.23300\n",
      "Epoch 184/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8642 - accuracy: 0.1670 - top3_accuracy: 0.3064 - top5_accuracy: 0.3862 - val_loss: 3.6456 - val_accuracy: 0.2286 - val_top3_accuracy: 0.3991 - val_top5_accuracy: 0.4835\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.23300\n",
      "Epoch 185/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8631 - accuracy: 0.1671 - top3_accuracy: 0.3043 - top5_accuracy: 0.3852 - val_loss: 3.1940 - val_accuracy: 0.2352 - val_top3_accuracy: 0.4031 - val_top5_accuracy: 0.4849\n",
      "\n",
      "Epoch 00185: val_accuracy improved from 0.23300 to 0.23520, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 186/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8669 - accuracy: 0.1679 - top3_accuracy: 0.3052 - top5_accuracy: 0.3863 - val_loss: 3.0855 - val_accuracy: 0.2262 - val_top3_accuracy: 0.3889 - val_top5_accuracy: 0.4799\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.23520\n",
      "Epoch 187/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8632 - accuracy: 0.1663 - top3_accuracy: 0.3043 - top5_accuracy: 0.3849 - val_loss: 3.2359 - val_accuracy: 0.2320 - val_top3_accuracy: 0.3923 - val_top5_accuracy: 0.4773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.23520\n",
      "Epoch 188/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8670 - accuracy: 0.1670 - top3_accuracy: 0.3039 - top5_accuracy: 0.3841 - val_loss: 3.5715 - val_accuracy: 0.2293 - val_top3_accuracy: 0.3965 - val_top5_accuracy: 0.4815\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.23520\n",
      "Epoch 189/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8567 - accuracy: 0.1690 - top3_accuracy: 0.3073 - top5_accuracy: 0.3885 - val_loss: 3.7100 - val_accuracy: 0.2338 - val_top3_accuracy: 0.3984 - val_top5_accuracy: 0.4863\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.23520\n",
      "Epoch 190/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8548 - accuracy: 0.1692 - top3_accuracy: 0.3066 - top5_accuracy: 0.3871 - val_loss: 3.3596 - val_accuracy: 0.2261 - val_top3_accuracy: 0.3906 - val_top5_accuracy: 0.4801\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.23520\n",
      "Epoch 191/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8592 - accuracy: 0.1680 - top3_accuracy: 0.3065 - top5_accuracy: 0.3877 - val_loss: 3.3687 - val_accuracy: 0.2309 - val_top3_accuracy: 0.3926 - val_top5_accuracy: 0.4738\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.23520\n",
      "Epoch 192/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8611 - accuracy: 0.1677 - top3_accuracy: 0.3045 - top5_accuracy: 0.3857 - val_loss: 3.4530 - val_accuracy: 0.2233 - val_top3_accuracy: 0.3760 - val_top5_accuracy: 0.4636\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.23520\n",
      "Epoch 193/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8541 - accuracy: 0.1690 - top3_accuracy: 0.3092 - top5_accuracy: 0.3887 - val_loss: 3.4917 - val_accuracy: 0.2315 - val_top3_accuracy: 0.3944 - val_top5_accuracy: 0.4770\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.23520\n",
      "Epoch 194/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.8502 - accuracy: 0.1697 - top3_accuracy: 0.3095 - top5_accuracy: 0.3904 - val_loss: 4.1913 - val_accuracy: 0.2268 - val_top3_accuracy: 0.3914 - val_top5_accuracy: 0.4806\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.23520\n",
      "Epoch 195/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8558 - accuracy: 0.1682 - top3_accuracy: 0.3063 - top5_accuracy: 0.3866 - val_loss: 2.1917 - val_accuracy: 0.2328 - val_top3_accuracy: 0.3923 - val_top5_accuracy: 0.4808\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.23520\n",
      "Epoch 196/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8383 - accuracy: 0.1697 - top3_accuracy: 0.3097 - top5_accuracy: 0.3921 - val_loss: 3.1584 - val_accuracy: 0.2308 - val_top3_accuracy: 0.4010 - val_top5_accuracy: 0.4813\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.23520\n",
      "Epoch 197/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8461 - accuracy: 0.1691 - top3_accuracy: 0.3080 - top5_accuracy: 0.3898 - val_loss: 3.2339 - val_accuracy: 0.2224 - val_top3_accuracy: 0.3836 - val_top5_accuracy: 0.4708\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.23520\n",
      "Epoch 198/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8498 - accuracy: 0.1702 - top3_accuracy: 0.3086 - top5_accuracy: 0.3900 - val_loss: 3.2551 - val_accuracy: 0.2335 - val_top3_accuracy: 0.4009 - val_top5_accuracy: 0.4923\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.23520\n",
      "Epoch 199/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.8378 - accuracy: 0.1708 - top3_accuracy: 0.3106 - top5_accuracy: 0.3920 - val_loss: 3.4679 - val_accuracy: 0.2290 - val_top3_accuracy: 0.3924 - val_top5_accuracy: 0.4774\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.23520\n",
      "Epoch 200/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8420 - accuracy: 0.1723 - top3_accuracy: 0.3109 - top5_accuracy: 0.3912 - val_loss: 3.4272 - val_accuracy: 0.2380 - val_top3_accuracy: 0.4006 - val_top5_accuracy: 0.4875\n",
      "\n",
      "Epoch 00200: val_accuracy improved from 0.23520 to 0.23800, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 201/300\n",
      "3125/3125 [==============================] - 186s 60ms/step - loss: 3.8463 - accuracy: 0.1707 - top3_accuracy: 0.3095 - top5_accuracy: 0.3913 - val_loss: 3.6193 - val_accuracy: 0.2194 - val_top3_accuracy: 0.3764 - val_top5_accuracy: 0.4656\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.23800\n",
      "Epoch 202/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.8372 - accuracy: 0.1711 - top3_accuracy: 0.3113 - top5_accuracy: 0.3914 - val_loss: 3.7400 - val_accuracy: 0.2316 - val_top3_accuracy: 0.3944 - val_top5_accuracy: 0.4817\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.23800\n",
      "Epoch 203/300\n",
      "3125/3125 [==============================] - 186s 59ms/step - loss: 3.8370 - accuracy: 0.1701 - top3_accuracy: 0.3100 - top5_accuracy: 0.3915 - val_loss: 3.1423 - val_accuracy: 0.2424 - val_top3_accuracy: 0.4028 - val_top5_accuracy: 0.4909\n",
      "\n",
      "Epoch 00203: val_accuracy improved from 0.23800 to 0.24240, saving model to models/AlphaNet_v2/AlphaNet_v2.h5\n",
      "Epoch 204/300\n",
      "3125/3125 [==============================] - 185s 59ms/step - loss: 3.8331 - accuracy: 0.1708 - top3_accuracy: 0.3107 - top5_accuracy: 0.3928 - val_loss: 3.4172 - val_accuracy: 0.2348 - val_top3_accuracy: 0.3965 - val_top5_accuracy: 0.4813\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.24240\n",
      "Epoch 205/300\n",
      "3125/3125 [==============================] - 187s 60ms/step - loss: 3.8331 - accuracy: 0.1724 - top3_accuracy: 0.3126 - top5_accuracy: 0.3938 - val_loss: 3.8989 - val_accuracy: 0.2329 - val_top3_accuracy: 0.3944 - val_top5_accuracy: 0.4788\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.24240\n",
      "Epoch 206/300\n",
      "1915/3125 [=================>............] - ETA: 1:07 - loss: 3.8358 - accuracy: 0.1723 - top3_accuracy: 0.3136 - top5_accuracy: 0.3937"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0753f5e00669>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mdatagen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 cb_list=cb_list)\n\u001b[0m",
      "\u001b[1;32mC:\\Projects\\cvproject-genclass\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model_path, restore, epochs, model, optim, datagen, data, cb_list, batch_size)\u001b[0m\n\u001b[0;32m     37\u001b[0m                                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                                     validation_steps=len(X_val) / batch_size)\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optim = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "history = train(model_path=model_path, \n",
    "                restore=False, \n",
    "                epochs=300,\n",
    "                model=model, \n",
    "                optim=optim,\n",
    "                datagen=datagen,\n",
    "                data=data, \n",
    "                cb_list=cb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the model and makes predictions on the test set\n",
    "custom_metrics = {\n",
    "    \"top3_accuracy\": top3_acc,\n",
    "    \"top5_accuracy\": top5_acc\n",
    "}\n",
    "model = load_model(model_path, custom_objects=custom_metrics)\n",
    "output = model.predict_generator(testgen.flow(X_test, shuffle=False))\n",
    "results = []\n",
    "\n",
    "for result in output:\n",
    "    results.append(labels[np.argmax(result)])\n",
    "    \n",
    "assert len(results) == len(X_test)\n",
    "print(\"Test images predicted:\", len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This writes the test set predictions to file\n",
    "with open(model_prefix + \" Predictions.txt\", \"w\") as test_file:\n",
    "    for i in range(len(results)):\n",
    "        test_file.write(test_images[i] + \" \" + results[i] + \"\\n\")\n",
    "    print(\"Predictions saved at\", test_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows some test set images and the model's predictions on them\n",
    "display_dim = 128\n",
    "for _ in range(10):\n",
    "    index = np.random.randint(len(X_test))\n",
    "    img = Image.fromarray(X_test[index], \"RGB\").resize(size=(display_dim, display_dim))\n",
    "    word_label = words[results[index]]\n",
    "    display(img)\n",
    "    print(word_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves an HTML version of the notebook for later viewing\n",
    "os.system(\"%notebook 'Training'\")\n",
    "os.system(\"jupyter nbconvert --to html Training.ipynb\")\n",
    "\n",
    "html_path = model_prefix + \".html\"\n",
    "if path.exists(html_path):\n",
    "    os.remove(html_path)\n",
    "os.rename(\"Training.html\", html_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
