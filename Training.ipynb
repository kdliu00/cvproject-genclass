{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train import *\n",
    "from models import *\n",
    "from tools import *\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data()\n",
    "X_val, y_val = load_data(\"val\")\n",
    "X_test, _ = load_data(\"test\")\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "print(\"Input shape: \" + str(input_shape))\n",
    "print(X_train[0][0][0])\n",
    "\n",
    "y_train = to_categorical(y_train, 200)\n",
    "y_val = to_categorical(y_val, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_label_dict()\n",
    "words = get_word_labels()\n",
    "\n",
    "test_images = os.listdir(\"data/tiny-imagenet-200/test/images/\")\n",
    "assert len(X_test) == len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Image preprocessing for the data\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, \n",
    "                             shear_range=20., \n",
    "                             zoom_range=0.4, \n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2, \n",
    "                             channel_shift_range=0.1, \n",
    "                             fill_mode=\"reflect\", \n",
    "                             preprocessing_function=shuffle_channels)\n",
    "\n",
    "testgen = ImageDataGenerator()\n",
    "\n",
    "data = {\"train\": (X_train, y_train), \n",
    "        \"val\": (X_val, y_val)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = BravoNet(input_shape, \"v3\", net34=True)\n",
    "model_prefix = \"models/\" + model.name + \"/\" + model.name\n",
    "model_path = model_prefix + \".h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the best model based on monitor value between epochs\n",
    "checkpoint = ModelCheckpoint(model_path, \n",
    "                             monitor=\"val_accuracy\", \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             period=1)\n",
    "\n",
    "# Stops training early when no improvement for monitor value\n",
    "early_stop = EarlyStopping(monitor=\"val_accuracy\", \n",
    "                           min_delta=0, \n",
    "                           patience=10, \n",
    "                           verbose=1)\n",
    "\n",
    "# Reduces learning rate when monitor value plateaus\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_accuracy\", \n",
    "                              factor=0.316, \n",
    "                              patience=5, \n",
    "                              verbose=1)\n",
    "\n",
    "# Logs training data to CSV\n",
    "restore = False # Whether or not we want to restore weights and continue training from a previous session\n",
    "csv_log = CSVLogger(model_prefix + \".csv\", separator=',', append=restore)\n",
    "\n",
    "cb_list = [checkpoint, early_stop, reduce_lr, csv_log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optim = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "history = train(model_path=model_path, \n",
    "                restore=restore, \n",
    "                epochs=300,\n",
    "                model=model, \n",
    "                optim=optim, \n",
    "                datagen=datagen, \n",
    "                testgen=testgen, \n",
    "                data=data, \n",
    "                cb_list=cb_list, \n",
    "                batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the model and makes predictions on the test set\n",
    "custom_metrics = {\n",
    "    \"top3_accuracy\": top3_acc,\n",
    "    \"top5_accuracy\": top5_acc\n",
    "}\n",
    "model = load_model(model_path, custom_objects=custom_metrics)\n",
    "output = model.predict(X_test)\n",
    "results = []\n",
    "\n",
    "for result in output:\n",
    "    results.append(labels[np.argmax(result)])\n",
    "    \n",
    "assert len(results) == len(X_test)\n",
    "print(\"Test images predicted:\", len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This writes the test set predictions to file\n",
    "with open(model_prefix + \" Predictions.txt\", \"w\") as test_file:\n",
    "    for i in range(len(results)):\n",
    "        test_file.write(test_images[i] + \" \" + results[i] + \"\\n\")\n",
    "    print(\"Predictions saved at\", test_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This shows some test set images and the model's predictions on them\n",
    "display_dim = 128\n",
    "for _ in range(10):\n",
    "    index = np.random.randint(len(X_test))\n",
    "    word_label = words[results[index]]\n",
    "    plt.plot()\n",
    "    plt.title(word_label)\n",
    "    plt.imshow(X_test[index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves an HTML version of the notebook for later viewing\n",
    "# NOTE: Make sure to check if the html was completely saved, sometimes it doesn't\n",
    "from nbconvert import HTMLExporter\n",
    "import codecs\n",
    "import nbformat\n",
    "exporter = HTMLExporter()\n",
    "output_notebook = nbformat.read(\"Training.ipynb\", as_version=nbformat.NO_CONVERT)\n",
    "output, resources = exporter.from_notebook_node(output_notebook)\n",
    "codecs.open(model_prefix + \".html\", \"w\").write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
