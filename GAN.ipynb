{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.2.0rc4\n",
      "  Downloading tensorflow-2.2.0rc4-cp37-cp37m-macosx_10_11_x86_64.whl (175.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 175.3 MB 9.9 MB/s eta 0:00:013    |██                              | 10.9 MB 14.6 MB/s eta 0:00:12     |█████████████████████████       | 136.8 MB 11.6 MB/s eta 0:00:04     |█████████████████████████▏      | 137.9 MB 11.6 MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: keras==2.3.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (2.3.1)\n",
      "Collecting numpy==1.18.3\n",
      "  Downloading numpy-1.18.3-cp37-cp37m-macosx_10_9_x86_64.whl (15.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.1 MB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python==4.2.0.34\n",
      "  Downloading opencv_python-4.2.0.34-cp37-cp37m-macosx_10_9_x86_64.whl (49.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 49.1 MB 3.8 MB/s eta 0:00:011     |██████████████████████████████▌ | 46.7 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib==3.2.1\n",
      "  Downloading matplotlib-3.2.1-cp37-cp37m-macosx_10_9_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 545 kB/s eta 0:00:01    |███████▏                        | 2.8 MB 541 kB/s eta 0:00:18\n",
      "\u001b[?25hCollecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: jupyter in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.9.0)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (3.11.3)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.33.4)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.1.8)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Using cached h5py-2.10.0-cp37-cp37m-macosx_10_6_intel.whl (3.0 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (3.1.0)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.1-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 16.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 22.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.12.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.27.2)\n",
      "Requirement already satisfied: pyyaml in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from keras==2.3.1->-r requirements.txt (line 2)) (5.1.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from keras==2.3.1->-r requirements.txt (line 2)) (1.0.8)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 5)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from sklearn->-r requirements.txt (line 6)) (0.21.2)\n",
      "Requirement already satisfied: jupyter-console in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (6.0.0)\n",
      "Requirement already satisfied: nbconvert in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (5.5.0)\n",
      "Requirement already satisfied: ipywidgets in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (7.5.0)\n",
      "Requirement already satisfied: ipykernel in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: notebook in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (6.0.0)\n",
      "Requirement already satisfied: qtconsole in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (4.5.1)\n",
      "Requirement already satisfied: setuptools in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (41.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (2.22.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.13.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)\n",
      "\u001b[K     |████████████████████████████████| 777 kB 24.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.15.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (0.13.2)\n",
      "Requirement already satisfied: jupyter_client in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 7)) (5.3.1)\n",
      "Requirement already satisfied: ipython in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 7)) (7.6.1)\n",
      "Requirement already satisfied: prompt_toolkit<2.1.0,>=2.0.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 7)) (2.0.9)\n",
      "Requirement already satisfied: pygments in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 7)) (2.4.2)\n",
      "Requirement already satisfied: defusedxml in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.6.0)\n",
      "Requirement already satisfied: jupyter-core in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (4.5.0)\n",
      "Requirement already satisfied: testpath in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (4.3.2)\n",
      "Requirement already satisfied: jinja2>=2.4 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (2.10.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.3)\n",
      "Requirement already satisfied: nbformat>=4.4 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (4.4.0)\n",
      "Requirement already satisfied: bleach in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.8.4)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (6.0.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (18.0.0)\n",
      "Requirement already satisfied: ipython-genutils in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (0.7.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (2019.6.16)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (4.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: backcall in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 7)) (0.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 7)) (4.7.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 7)) (0.13.3)\n",
      "Requirement already satisfied: pickleshare in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 7)) (0.7.5)\n",
      "Requirement already satisfied: decorator in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 7)) (4.4.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 7)) (0.1.0)\n",
      "Requirement already satisfied: wcwidth in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from prompt_toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->-r requirements.txt (line 7)) (0.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jinja2>=2.4->nbconvert->jupyter->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbformat>=4.4->nbconvert->jupyter->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: webencodings in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 7)) (0.5.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython->jupyter-console->jupyter->-r requirements.txt (line 7)) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython->jupyter-console->jupyter->-r requirements.txt (line 7)) (0.5.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter->-r requirements.txt (line 7)) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter->-r requirements.txt (line 7)) (0.14.11)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=4aabc011fa239f9e59837a7b46ed2e76e5f86861ccdff12e975800a0b6d4e692\n",
      "  Stored in directory: /Users/sofiapaganin/Library/Caches/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: astunparse, gast, numpy, h5py, tensorboard-plugin-wit, tensorboard, tensorflow-estimator, tensorflow, opencv-python, matplotlib, sklearn\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.1\n",
      "    Uninstalling numpy-1.18.1:\n",
      "      Successfully uninstalled numpy-1.18.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.9.0\n",
      "    Uninstalling h5py-2.9.0:\n",
      "      Successfully uninstalled h5py-2.9.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.1.0\n",
      "    Uninstalling tensorflow-2.1.0:\n",
      "      Successfully uninstalled tensorflow-2.1.0\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.2.0.32\n",
      "    Uninstalling opencv-python-4.2.0.32:\n",
      "      Successfully uninstalled opencv-python-4.2.0.32\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.1.1\n",
      "    Uninstalling matplotlib-3.1.1:\n",
      "      Successfully uninstalled matplotlib-3.1.1\n",
      "Successfully installed astunparse-1.6.3 gast-0.3.3 h5py-2.10.0 matplotlib-3.2.1 numpy-1.18.3 opencv-python-4.2.0.34 sklearn-0.0 tensorboard-2.2.1 tensorboard-plugin-wit-1.6.0.post3 tensorflow-2.2.0rc4 tensorflow-estimator-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 512\n",
    "EPOCHS = 10\n",
    "OUTPUT_DIR = \"img\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data\n",
      "\n",
      "Finished loading train data\n",
      "\n",
      "Loading val data\n",
      "\n",
      "Finished loading val data\n",
      "\n",
      "Loading test data\n",
      "\n",
      "Finished loading test data\n",
      "\n",
      "Loading labels\n",
      "\n",
      "Done\n",
      "\n",
      "Loading words\n",
      "\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data()\n",
    "X_val, y_val = load_data(\"val\")\n",
    "X_test, _ = load_data(\"test\")\n",
    "\n",
    "y_train = to_categorical(y_train, 200)\n",
    "y_val = to_categorical(y_val, 200)\n",
    "\n",
    "labels = get_label_dict()\n",
    "words = get_word_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.Model):\n",
    "    \n",
    "    def __init__(self, random_noise_size = 100):\n",
    "        super().__init__(name='generator')\n",
    "        #layers\n",
    "        self.input_layer = keras.layers.Dense(units = random_noise_size)\n",
    "        self.dense_1 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_1 =  keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_2 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_2 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_3 = keras.layers.Dense(units = 256)\n",
    "        self.leaky_3 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.output_layer = keras.layers.Dense(units=3, activation = \"tanh\")\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        ## Definition of Forward Pass\n",
    "        x = self.input_layer(input_tensor)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.leaky_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.leaky_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        x = self.leaky_3(x)\n",
    "        return  self.output_layer(x)\n",
    "    \n",
    "    def generate_noise(self,batch_size, random_noise_size):\n",
    "        return np.random.uniform(-1,1, size = (batch_size, random_noise_size, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__(name = \"discriminator\")\n",
    "        \n",
    "        #Layers\n",
    "        self.input_layer = keras.layers.Dense(units = 3)\n",
    "        self.dense_1 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_1 =  keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_2 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_2 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_3 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_3 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        \n",
    "        self.logits = keras.layers.Dense(units = 1)  # This neuron tells us if the input is fake or real\n",
    "    def call(self, input_tensor):\n",
    "          ## Definition of Forward Pass\n",
    "        x = self.input_layer(input_tensor)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.leaky_1(x)\n",
    "        x = self.leaky_2(x)\n",
    "        x = self.leaky_3(x)\n",
    "        x = self.leaky_3(x)\n",
    "        x = self.logits(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator  = Discriminator()\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_objective(dx_of_gx):\n",
    "    # Labels are true here because generator thinks he produces real images. \n",
    "    return cross_entropy(tf.ones_like(dx_of_gx), dx_of_gx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_objective(real_output, fake_output, smoothing_factor=0.9):\n",
    "    \"\"\"\n",
    "    label = 0: fake\n",
    "    label = 1: real\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output * smoothing_factor, real_output))\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    \n",
    "    return real_loss + fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = keras.optimizers.RMSprop()\n",
    "discriminator_optimizer = keras.optimizers.RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def training_step(generator: Generator, discriminator: Discriminator, images:np.ndarray , k:int=1, batch_size=32):\n",
    "    for _ in range(k):\n",
    "         with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            noise = generator.generate_noise(batch_size, 64)\n",
    "            g_z = generator(noise)\n",
    "            print(type(g_z))\n",
    "            print(\"G_Z: \", g_z.shape)\n",
    "            images = tf.cast(images, tf.float32)\n",
    "            d_x_true = discriminator(images) # Trainable?\n",
    "            print(\"IMAGES: \", images.shape)\n",
    "            \n",
    "            d_x_fake = discriminator(g_z) # dx_of_gx\n",
    "            print(d_x_fake.shape)\n",
    "            print(type(d_x_fake))\n",
    "            discriminator_loss = discriminator_objective(d_x_true, d_x_fake)\n",
    "            # Adjusting Gradient of Discriminator\n",
    "            disc_grad = disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "            discriminator_optimizer.apply_gradients(zip(disc_grad, discriminator.trainable_variables)) # Takes a list of gradient and variables pairs\n",
    "            \n",
    "              \n",
    "            generator_loss = generator_objective(d_x_fake)\n",
    "            # Adjusting Gradient of Generator\n",
    "            gen_grad = gen_tape.gradient(generator_loss, generator.trainable_variables)\n",
    "            generator_optimizer.apply_gradients(zip(gen_grad, generator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(dataset, epoches):\n",
    "    for epoch in range(epoches):\n",
    "        for batch in dataset: \n",
    "            print(type(batch))\n",
    "            print(type(epoches))\n",
    "            print(type(BATCH_SIZE))\n",
    "            print(type(generator))\n",
    "            print(type(discriminator))\n",
    "            training_step(generator, discriminator, batch, k=1, batch_size=BATCH_SIZE)\n",
    "            \n",
    "        ## After ith epoch plot image \n",
    "        if (epoch % 50) == 0: \n",
    "            fake_image = tf.reshape(generator(seed), shape=(28,28))\n",
    "            print(\"{}/{} epoches\".format(epoch, epoches))\n",
    "            #plt.imshow(fake_image, cmap = \"gray\")\n",
    "            plt.imsave(\"{}/{}.png\".format(OUTPUT_DIR,epoch),fake_image, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class '__main__.Generator'>\n",
      "<class '__main__.Discriminator'>\n",
      "WARNING:tensorflow:Layer generator is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "G_Z:  (256, 64, 3)\n",
      "IMAGES:  (64, 64, 3)\n",
      "(256, 64, 1)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-143-00af8eb356cd>:16 training_step  *\n        discriminator_loss = discriminator_objective(d_x_true, d_x_fake)\n    <ipython-input-141-be87a2d736ce>:6 discriminator_objective  *\n        real_loss = cross_entropy(tf.ones_like(real_output * smoothing_factor, real_output))\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper\n        \n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:2613 ones_like_v2\n        \n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:2623 ones_like_impl\n        \n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:2652 ones\n        \n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/dtypes.py:720 as_dtype\n        \n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:705 __hash__\n        \n\n    TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-144-97484235564f>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(dataset, epoches)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m## After ith epoch plot image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-143-00af8eb356cd>:16 training_step  *\n        discriminator_loss = discriminator_objective(d_x_true, d_x_fake)\n    <ipython-input-141-be87a2d736ce>:6 discriminator_objective  *\n        real_loss = cross_entropy(tf.ones_like(real_output * smoothing_factor, real_output))\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper\n        \n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:2613 ones_like_v2\n        \n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:2623 ones_like_impl\n        \n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:2652 ones\n        \n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/dtypes.py:720 as_dtype\n        \n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:705 __hash__\n        \n\n    TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training(X_train, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [1,100], In[1]: [3,100] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-4c65f4fcde5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfake_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-136-a4c7b705c163>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m## Definition of Forward Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul_eager_fallback\u001b[0;34m(a, b, transpose_a, transpose_b, name, ctx)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [1,100], In[1]: [3,100] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "fake_image = generator(np.random.uniform(-1,1, size = (1, 100)))\n",
    "plt.imshow(tf.reshape(fake_image, shape = (28,28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
