{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.2.0rc4 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (2.2.0rc4)\n",
      "Requirement already satisfied: keras==2.3.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (2.3.1)\n",
      "Requirement already satisfied: numpy==1.18.3 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.18.3)\n",
      "Requirement already satisfied: opencv-python==4.2.0.34 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (4.2.0.34)\n",
      "Requirement already satisfied: matplotlib==3.2.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (3.2.1)\n",
      "Requirement already satisfied: sklearn in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (0.0)\n",
      "Requirement already satisfied: jupyter in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.33.4)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.3.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.12.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.27.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (3.11.3)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.1.8)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.11.2)\n",
      "Requirement already satisfied: pyyaml in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from keras==2.3.1->-r requirements.txt (line 2)) (5.1.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from keras==2.3.1->-r requirements.txt (line 2)) (1.0.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 5)) (0.10.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from sklearn->-r requirements.txt (line 6)) (0.21.2)\n",
      "Requirement already satisfied: nbconvert in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (5.5.0)\n",
      "Requirement already satisfied: notebook in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (6.0.0)\n",
      "Requirement already satisfied: ipykernel in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: ipywidgets in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (7.5.0)\n",
      "Requirement already satisfied: jupyter-console in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (6.0.0)\n",
      "Requirement already satisfied: qtconsole in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 7)) (4.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (2.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.15.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.6.0.post3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (41.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (0.13.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: jinja2>=2.4 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (2.10.1)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.8.4)\n",
      "Requirement already satisfied: testpath in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: defusedxml in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (0.6.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (4.3.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter-core in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (4.5.0)\n",
      "Requirement already satisfied: bleach in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: nbformat>=4.4 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (4.4.0)\n",
      "Requirement already satisfied: pygments in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 7)) (2.4.2)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: Send2Trash in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (0.7.1)\n",
      "Requirement already satisfied: jupyter-client>=5.3.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (5.3.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (18.0.0)\n",
      "Requirement already satisfied: tornado>=5.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (6.0.3)\n",
      "Requirement already satisfied: ipython-genutils in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipykernel->jupyter->-r requirements.txt (line 7)) (7.6.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: prompt_toolkit<2.1.0,>=2.0.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 7)) (2.0.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (4.1.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jinja2>=2.4->nbconvert->jupyter->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: decorator in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->nbconvert->jupyter->-r requirements.txt (line 7)) (4.4.0)\n",
      "Requirement already satisfied: webencodings in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 7)) (0.5.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from nbformat>=4.4->nbconvert->jupyter->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: backcall in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (0.1.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (0.13.3)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (4.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from prompt_toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->-r requirements.txt (line 7)) (0.1.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0rc4->-r requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter->-r requirements.txt (line 7)) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter->-r requirements.txt (line 7)) (0.14.11)\n",
      "Requirement already satisfied: parso>=0.3.0 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (0.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 7)) (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 100000\n",
    "EPOCHS = 1\n",
    "OUTPUT_DIR = \"img\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data\n",
      "\n",
      "Finished loading train data\n",
      "\n",
      "Loading val data\n",
      "\n",
      "Finished loading val data\n",
      "\n",
      "Loading test data\n",
      "\n",
      "Finished loading test data\n",
      "\n",
      "Loading labels\n",
      "\n",
      "Done\n",
      "\n",
      "Loading words\n",
      "\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data()\n",
    "X_val, y_val = load_data(\"val\")\n",
    "X_test, _ = load_data(\"test\")\n",
    "\n",
    "y_train = to_categorical(y_train, 200)\n",
    "y_val = to_categorical(y_val, 200)\n",
    "\n",
    "labels = get_label_dict()\n",
    "words = get_word_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 64, 64, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.Model):\n",
    "    \n",
    "    def __init__(self, random_noise_size = 100):\n",
    "        super().__init__(name='generator')\n",
    "        #layers\n",
    "        self.input_layer = keras.layers.Dense(units = random_noise_size)\n",
    "        self.dense_1 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_1 =  keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_2 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_2 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_3 = keras.layers.Dense(units = 256)\n",
    "        self.leaky_3 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.output_layer = keras.layers.Dense(units=3, activation = \"tanh\")\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        ## Definition of Forward Pass\n",
    "        x = self.input_layer(input_tensor)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.leaky_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.leaky_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        x = self.leaky_3(x)\n",
    "        return  self.output_layer(x)\n",
    "    \n",
    "    def generate_noise(self,batch_size, random_noise_size):\n",
    "        return np.random.uniform(-1,1, size = (batch_size, random_noise_size, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__(name = \"discriminator\")\n",
    "        \n",
    "        #Layers\n",
    "        self.input_layer = keras.layers.Dense(units = 1, input_shape=(64, 64, 3))\n",
    "        self.dense_1 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_1 =  keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_2 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_2 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_3 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_3 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        \n",
    "        self.logits = keras.layers.Dense(units = 1)  # This neuron tells us if the input is fake or real\n",
    "    def call(self, input_tensor):\n",
    "          ## Definition of Forward Pass\n",
    "        x = self.input_layer(input_tensor)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.leaky_1(x)\n",
    "        x = self.leaky_2(x)\n",
    "        x = self.leaky_3(x)\n",
    "        x = self.leaky_3(x)\n",
    "        x = self.logits(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator  = Discriminator()\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_objective(dx_of_gx):\n",
    "    # Labels are true here because generator thinks he produces real images. \n",
    "    \n",
    "    return cross_entropy(tf.ones_like(dx_of_gx), dx_of_gx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_objective(real_output, fake_output, smoothing_factor=0.9):\n",
    "    \"\"\"\n",
    "    label = 0: fake\n",
    "    label = 1: real\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output * smoothing_factor, real_output.ref()))\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    \n",
    "    return real_loss + fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = keras.optimizers.RMSprop()\n",
    "discriminator_optimizer = keras.optimizers.RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def training_step(generator: Generator, discriminator: Discriminator, images:np.ndarray , k:int=1, batch_size=32):\n",
    "    for _ in range(k):\n",
    "         with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            noise = generator.generate_noise(batch_size, 64)\n",
    "#             print(g_z.shape)\n",
    "            g_z = generator(noise)\n",
    "\n",
    "            images = tf.cast(images, tf.float32)\n",
    "            d_x_true = discriminator(images) # Trainable?\n",
    "            \n",
    "            d_x_fake = discriminator(g_z) # dx_of_gx\n",
    "\n",
    "            \n",
    "            discriminator_loss = discriminator_objective(d_x_true, d_x_fake)\n",
    "            # Adjusting Gradient of Discriminator\n",
    "            disc_grad = disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "            discriminator_optimizer.apply_gradients(zip(disc_grad, discriminator.trainable_variables)) # Takes a list of gradient and variables pairs\n",
    "            \n",
    "              \n",
    "            generator_loss = generator_objective(d_x_fake)\n",
    "            # Adjusting Gradient of Generator\n",
    "            gen_grad = gen_tape.gradient(generator_loss, generator.trainable_variables)\n",
    "            generator_optimizer.apply_gradients(zip(gen_grad, generator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.uniform(-1,1, size = (1, 100)) # generating some noise for the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(dataset, epoches):\n",
    "    for epoch in range(epoches):\n",
    "        for batch in dataset: \n",
    "#             print(type(batch))\n",
    "#             print(type(epoches))\n",
    "#             print(type(BATCH_SIZE))\n",
    "#             print(type(generator))\n",
    "#             print(type(discriminator))\n",
    "            training_step(generator, discriminator, batch, k=1, batch_size=BATCH_SIZE)\n",
    "            \n",
    "        ## After ith epoch plot image \n",
    "        if (epoch % 50) == 0: \n",
    "            fake_image = tf.reshape(generator(seed), shape=(28,28))\n",
    "            print(\"{}/{} epoches\".format(epoch, epoches))\n",
    "            #plt.imshow(fake_image, cmap = \"gray\")\n",
    "            plt.imsave(\"{}/{}.png\".format(OUTPUT_DIR,epoch),fake_image, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    <ipython-input-111-c96fecbe8241>:15 training_step  *\n        discriminator_loss = discriminator_objective(d_x_true, d_x_fake)\n    <ipython-input-109-98d251d86973>:6 discriminator_objective  *\n        real_loss = cross_entropy(tf.ones_like(real_output * smoothing_factor, real_output.ref()))\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180 wrapper  **\n        return target(*args, **kwargs)\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2918 ones_like_v2\n        return ones_like_impl(input, dtype, name, optimize=True)\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2928 ones_like_impl\n        ret = ones(ones_shape, dtype=dtype, name=name)\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2959 ones\n        dtype = dtypes.as_dtype(dtype).base_dtype\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:643 as_dtype\n        (type_value,))\n\n    TypeError: Cannot convert value <Reference wrapping <tf.Tensor 'discriminator/dense_54/BiasAdd:0' shape=(64, 64, 1) dtype=float32>> to a TensorFlow DType.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-ae1ebaee5cd0>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(dataset, epoches)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#             print(type(generator))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#             print(type(discriminator))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m## After ith epoch plot image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-111-c96fecbe8241>:15 training_step  *\n        discriminator_loss = discriminator_objective(d_x_true, d_x_fake)\n    <ipython-input-109-98d251d86973>:6 discriminator_objective  *\n        real_loss = cross_entropy(tf.ones_like(real_output * smoothing_factor, real_output.ref()))\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180 wrapper  **\n        return target(*args, **kwargs)\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2918 ones_like_v2\n        return ones_like_impl(input, dtype, name, optimize=True)\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2928 ones_like_impl\n        ret = ones(ones_shape, dtype=dtype, name=name)\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2959 ones\n        dtype = dtypes.as_dtype(dtype).base_dtype\n    /Users/sofiapaganin/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:643 as_dtype\n        (type_value,))\n\n    TypeError: Cannot convert value <Reference wrapping <tf.Tensor 'discriminator/dense_54/BiasAdd:0' shape=(64, 64, 1) dtype=float32>> to a TensorFlow DType.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training(X_train, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0-rc4'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0-tf'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [1,100], In[1]: [3,100] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5566\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5567\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5568\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4c65f4fcde5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfake_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a4c7b705c163>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m## Definition of Forward Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5571\u001b[0m         return mat_mul_eager_fallback(\n\u001b[1;32m   5572\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5573\u001b[0;31m             ctx=_ctx)\n\u001b[0m\u001b[1;32m   5574\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5575\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul_eager_fallback\u001b[0;34m(a, b, transpose_a, transpose_b, name, ctx)\u001b[0m\n\u001b[1;32m   5612\u001b[0m   _attr_T)\n\u001b[1;32m   5613\u001b[0m   _result = _execute.execute(b\"MatMul\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 5614\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   5615\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5616\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [1,100], In[1]: [3,100] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "fake_image = generator(np.random.uniform(-1,1, size = (1, 100)))\n",
    "plt.imshow(tf.reshape(fake_image, shape = (28,28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
